{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1jixwOITC2bjIzZRc388tdtr1wOYlxE2f",
      "authorship_tag": "ABX9TyP94vrkQ6+yQBFo7zpzgHYo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leakydishes/Fairness_feedback_nlp_test/blob/main/Fairness_feedback_nlp_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Deakin University Internship 2023**\n",
        "##Human-Guided Fair Classification for NLP\n",
        "#####Te' Claire\n",
        "\n",
        "*@inproceedings{\n",
        "dorner2023humanguided,\n",
        "title={Human-Guided Fair Classification for Natural Language Processing},\n",
        "author={Florian E. Dorner and Momchil Peychev and Nikola Konstantinov and Naman Goel and Elliott Ash and Martin Vechev},\n",
        "booktitle={The Eleventh International Conference on Learning Representations },\n",
        "year={2023},\n",
        "url={https://openreview.net/forum?id=N_g8TT9Cy7f}\n",
        "}*"
      ],
      "metadata": {
        "id": "1krF2sLeA9Ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 1. Mount Google Drive**"
      ],
      "metadata": {
        "id": "rnMkrDpv5XY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuts1xQ2_yPd",
        "outputId": "4a7c74f4-b702-4ee2-f7b5-b1cba0d3e45a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 2.Download the train.csv file from the Civil comments dataset to Code/Datasets/Kaggle_Toxicity**\n",
        "####Set up a virtual environment with the required packages"
      ],
      "metadata": {
        "id": "riJuKYPvAzPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Note: Google Colab already has Python pre-installed therefore you don't need to create a virtual environment. Instead install dependencies."
      ],
      "metadata": {
        "id": "gg9i_BeQoFoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/fairness-feedback-nlp-master/Code"
      ],
      "metadata": {
        "id": "2FKZmY_S5tzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7aa29dd-3d05-44a4-a50c-52dd2dca6f5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/fairness-feedback-nlp-master/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Install python 3.8 and update"
      ],
      "metadata": {
        "id": "Tu6ZHHic10Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install python3.8\n",
        "!python3.8 -m ensurepip --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfnHxFukotDq",
        "outputId": "230293f9-e359-446e-f5a7-0e51256fa423"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 5,481 B/110 kB 5%] [Connecte\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/110 kB 13%] [2 InRel\r0% [Connecting to archive.ubuntu.com] [1 InRelease 28.6 kB/110 kB 26%] [Connect\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [108 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [419 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [969 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [848 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [802 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [863 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,085 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,219 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:18 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [35.7 kB]\n",
            "Fetched 6,608 kB in 3s (2,364 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support python3.8\n",
            "  python3.8-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 5,099 kB of archives.\n",
            "After this operation, 18.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.17-1+jammy1 [793 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.17-1+jammy1 [2,023 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.17-1+jammy1 [1,817 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.17-1+jammy1 [438 kB]\n",
            "Fetched 5,099 kB in 5s (1,128 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 120493 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.8-minimal_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../1-python3.8-minimal_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.8-stdlib_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../5-python3.8_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.17-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-minimal (3.8.17-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.17-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "/usr/bin/python3.8: No module named ensurepip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list python versions\n",
        "!ls /usr/bin/python*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMHuy1OAo9LZ",
        "outputId": "87cec052-6b1c-434a-c42b-fa946be0a3fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3     /usr/bin/python3.10-config  /usr/bin/python3-config\n",
            "/usr/bin/python3.10  /usr/bin/python3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#update python version\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1"
      ],
      "metadata": {
        "id": "Bm-ZnUMYqZUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1659e50f-1a15-4fd5-d034-77601083cba6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confirgure python version\n",
        "!sudo update-alternatives --config python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVGh3s64tzNV",
        "outputId": "34667730-46e4-4cd6-d7fa-d250fd0db704"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is only one alternative in link group python3 (providing /usr/bin/python3): /usr/bin/python3.8\n",
            "Nothing to configure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#permanently install the specific version to the google colab\n",
        "!sudo apt install python3-pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV2U9wrSt-DG",
        "outputId": "d7e6a40f-8017-4fce-fe56-1484a421c597"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,965 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.3 [1,305 kB]\n",
            "Fetched 1,677 kB in 0s (3,971 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 121144 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.3_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Check correct packages installed for distutils and Numpy"
      ],
      "metadata": {
        "id": "rY-Jb9V52SwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python3.8-distutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30gzRE2nuaLv",
        "outputId": "5c9c3456-1339-4a56-a3aa-471bbc3a5001"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.8-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.8-distutils python3.8-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 319 kB of archives.\n",
            "After this operation, 1,237 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.17-1+jammy1 [126 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.17-1+jammy1 [193 kB]\n",
            "Fetched 319 kB in 2s (189 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "(Reading database ... 122006 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.8-lib2to3_3.8.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../python3.8-distutils_3.8.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.17-1+jammy1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t1kEDf8K2Y_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall numpy==1.22.3\n",
        "#Check numpy version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UojJU7W0vZLC",
        "outputId": "9af06eb2-07e2-4f07-fadc-711db19fa25d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.22.3\n",
            "  Downloading numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "Successfully installed numpy-1.22.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Then, run"
      ],
      "metadata": {
        "id": "44Ju1GkUp0mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tpaYQnTPt8e0",
        "outputId": "ffecd5e6-18cc-4e66-b9d9-9ba28c746398"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.22.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.22.3)\n",
            "Collecting torch==1.11.0\n",
            "  Downloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.0\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.18.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.4.2\n",
            "  Downloading pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.6.3\n",
            "  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2023.6.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m736.6/736.6 KB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
            "Collecting python-dateutil>=2.8.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 KB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec\n",
            "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas==1.4.2->-r requirements.txt (line 5)) (1.16.0)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click\n",
            "  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib\n",
            "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 KB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=b9e43a717d06e3d31df8c43c795ac80f708d03397fbba1057908008e5e51d449\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, pytz, urllib3, typing-extensions, tqdm, scipy, regex, pyyaml, python-dateutil, packaging, joblib, idna, fsspec, filelock, click, charset-normalizer, certifi, torch, sacremoses, requests, pandas, huggingface-hub, transformers\n",
            "Successfully installed certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.6 filelock-3.12.2 fsspec-2023.6.0 huggingface-hub-0.16.4 idna-3.4 joblib-1.3.1 packaging-23.1 pandas-1.4.2 python-dateutil-2.8.2 pytz-2023.3 pyyaml-6.0.1 regex-2023.6.3 requests-2.31.0 sacremoses-0.0.53 scipy-1.6.3 tokenizers-0.12.1 torch-1.11.0 tqdm-4.64.0 transformers-4.18.0 typing-extensions-4.7.1 urllib3-2.0.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Check file path and script is granted permission to be executed as a program"
      ],
      "metadata": {
        "id": "lvyV7KCj2jOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/fairness-feedback-nlp-master/Code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMGoUHhtuexa",
        "outputId": "f7185641-7819-43bc-b245-b66b0ce35bbd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/fairness-feedback-nlp-master/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!chmod +x Generation.sh\n",
        "!chmod +x Generation_Quick.sh"
      ],
      "metadata": {
        "id": "mIXm04nczVm4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Additionally added Transfers"
      ],
      "metadata": {
        "id": "-b3ZSQ4S2y1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdVfDb6T0Z-5",
        "outputId": "f1c83e85-4f70-4bdc-e4e7-dd07b021b954"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.18.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "#### Add a click function in console to stop Google Collab from timing out\n",
        "#### NOTE: This does not work as google only gives 90min time on free plan, capcha box will appear and clicker no longer works as of 2023\n",
        "\n",
        "#### Declare function\n",
        "function ConnectButton() {\n",
        "    console.log(\"Working\");\n",
        "    document.querySelector(\"colab-toolbar-button\").click();\n",
        "}\n",
        "\n",
        "#### Define Function\n",
        "var connect = setInterval(ConnectButton, 100);\n",
        "\n",
        "\n",
        "#### stop\n",
        "clearInterval(connect)\n",
        "\n",
        "#### call back\n",
        "#### Define Function\n",
        "var connect = setInterval(ConnectButton, 100);\n"
      ],
      "metadata": {
        "id": "XD4oDLY34Vpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the code\n",
        "!./Generation_Quick.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBtK7CP3z0nk",
        "outputId": "65b0adc5-a437-4d83-f00d-ec48f2e23dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100% 481/481 [00:00<00:00, 2.03MB/s]\n",
            "Downloading: 100% 478M/478M [00:06<00:00, 74.1MB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Downloading: 100% 878k/878k [00:00<00:00, 16.5MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 10.7MB/s]\n",
            "216073\n",
            "21607\n",
            "epoch:  0\n",
            "Batch_loss $25.0357: 100% 12155/12155 [44:10<00:00,  4.59it/s]\n",
            "epoch:  1\n",
            "Batch_loss $73.8241: 100% 12155/12155 [44:08<00:00,  4.59it/s]\n",
            "epoch:  2\n",
            "Batch_loss $22.9123: 100% 12155/12155 [44:08<00:00,  4.59it/s]\n",
            "Testing on train\n",
            "100% 12155/12155 [12:17<00:00, 16.47it/s]\n",
            "train male\n",
            "tpr: tensor(0.9981, device='cuda:0')\n",
            "tnr: tensor(0.9488, device='cuda:0')\n",
            "loss: tensor(0.0122, device='cuda:0')\n",
            "train female\n",
            "tpr: tensor(0.9993, device='cuda:0')\n",
            "tnr: tensor(0.9410, device='cuda:0')\n",
            "loss: tensor(0.0105, device='cuda:0')\n",
            "train transgender\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9833, device='cuda:0')\n",
            "loss: tensor(0.0103, device='cuda:0')\n",
            "train other_gender\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2819, device='cuda:0')\n",
            "train heterosexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9436, device='cuda:0')\n",
            "loss: tensor(0.0146, device='cuda:0')\n",
            "train homosexual_gay_or_lesbian\n",
            "tpr: tensor(0.9980, device='cuda:0')\n",
            "tnr: tensor(0.9881, device='cuda:0')\n",
            "loss: tensor(0.0045, device='cuda:0')\n",
            "train bisexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.6452, device='cuda:0')\n",
            "loss: tensor(0.0454, device='cuda:0')\n",
            "train other_sexual_orientation\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.3225, device='cuda:0')\n",
            "train christian\n",
            "tpr: tensor(0.9999, device='cuda:0')\n",
            "tnr: tensor(0.9291, device='cuda:0')\n",
            "loss: tensor(0.0137, device='cuda:0')\n",
            "train jewish\n",
            "tpr: tensor(0.9990, device='cuda:0')\n",
            "tnr: tensor(0.9897, device='cuda:0')\n",
            "loss: tensor(0.0031, device='cuda:0')\n",
            "train muslim\n",
            "tpr: tensor(0.9997, device='cuda:0')\n",
            "tnr: tensor(0.9814, device='cuda:0')\n",
            "loss: tensor(0.0051, device='cuda:0')\n",
            "train hindu\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9912, device='cuda:0')\n",
            "loss: tensor(0.0085, device='cuda:0')\n",
            "train buddhist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9905, device='cuda:0')\n",
            "loss: tensor(0.0100, device='cuda:0')\n",
            "train atheist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9972, device='cuda:0')\n",
            "loss: tensor(0.0044, device='cuda:0')\n",
            "train other_religion\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.0022, device='cuda:0')\n",
            "loss: tensor(0.1342, device='cuda:0')\n",
            "train black\n",
            "tpr: tensor(0.9990, device='cuda:0')\n",
            "tnr: tensor(0.9902, device='cuda:0')\n",
            "loss: tensor(0.0034, device='cuda:0')\n",
            "train white\n",
            "tpr: tensor(0.9993, device='cuda:0')\n",
            "tnr: tensor(0.9915, device='cuda:0')\n",
            "loss: tensor(0.0035, device='cuda:0')\n",
            "train asian\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9712, device='cuda:0')\n",
            "loss: tensor(0.0078, device='cuda:0')\n",
            "train latino\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9641, device='cuda:0')\n",
            "loss: tensor(0.0198, device='cuda:0')\n",
            "train other_race_or_ethnicity\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.3107, device='cuda:0')\n",
            "loss: tensor(0.0948, device='cuda:0')\n",
            "train physical_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.0384, device='cuda:0')\n",
            "loss: tensor(0.1292, device='cuda:0')\n",
            "train intellectual_or_learning_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.7418, device='cuda:0')\n",
            "loss: tensor(0.0481, device='cuda:0')\n",
            "train psychiatric_or_mental_illness\n",
            "tpr: tensor(0.9994, device='cuda:0')\n",
            "tnr: tensor(0.9619, device='cuda:0')\n",
            "loss: tensor(0.0091, device='cuda:0')\n",
            "train other_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2844, device='cuda:0')\n",
            "Testing on test\n",
            "100% 1351/1351 [01:22<00:00, 16.42it/s]\n",
            "test male\n",
            "tpr: tensor(0.9994, device='cuda:0')\n",
            "tnr: tensor(0.9464, device='cuda:0')\n",
            "loss: tensor(0.0126, device='cuda:0')\n",
            "test female\n",
            "tpr: tensor(0.9995, device='cuda:0')\n",
            "tnr: tensor(0.9414, device='cuda:0')\n",
            "loss: tensor(0.0106, device='cuda:0')\n",
            "test transgender\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9810, device='cuda:0')\n",
            "loss: tensor(0.0105, device='cuda:0')\n",
            "test other_gender\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2819, device='cuda:0')\n",
            "test heterosexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9436, device='cuda:0')\n",
            "loss: tensor(0.0150, device='cuda:0')\n",
            "test homosexual_gay_or_lesbian\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9884, device='cuda:0')\n",
            "loss: tensor(0.0045, device='cuda:0')\n",
            "test bisexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.6399, device='cuda:0')\n",
            "loss: tensor(0.0456, device='cuda:0')\n",
            "test other_sexual_orientation\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.3230, device='cuda:0')\n",
            "test christian\n",
            "tpr: tensor(0.9990, device='cuda:0')\n",
            "tnr: tensor(0.9273, device='cuda:0')\n",
            "loss: tensor(0.0139, device='cuda:0')\n",
            "test jewish\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9898, device='cuda:0')\n",
            "loss: tensor(0.0031, device='cuda:0')\n",
            "test muslim\n",
            "tpr: tensor(0.9986, device='cuda:0')\n",
            "tnr: tensor(0.9818, device='cuda:0')\n",
            "loss: tensor(0.0051, device='cuda:0')\n",
            "test hindu\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9911, device='cuda:0')\n",
            "loss: tensor(0.0085, device='cuda:0')\n",
            "test buddhist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9902, device='cuda:0')\n",
            "loss: tensor(0.0100, device='cuda:0')\n",
            "test atheist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9972, device='cuda:0')\n",
            "loss: tensor(0.0044, device='cuda:0')\n",
            "test other_religion\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.0022, device='cuda:0')\n",
            "loss: tensor(0.1350, device='cuda:0')\n",
            "test black\n",
            "tpr: tensor(0.9978, device='cuda:0')\n",
            "tnr: tensor(0.9906, device='cuda:0')\n",
            "loss: tensor(0.0036, device='cuda:0')\n",
            "test white\n",
            "tpr: tensor(0.9966, device='cuda:0')\n",
            "tnr: tensor(0.9920, device='cuda:0')\n",
            "loss: tensor(0.0035, device='cuda:0')\n",
            "test asian\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9700, device='cuda:0')\n",
            "loss: tensor(0.0080, device='cuda:0')\n",
            "test latino\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9627, device='cuda:0')\n",
            "loss: tensor(0.0200, device='cuda:0')\n",
            "test other_race_or_ethnicity\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.3037, device='cuda:0')\n",
            "loss: tensor(0.0953, device='cuda:0')\n",
            "test physical_disability\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0.0384, device='cuda:0')\n",
            "loss: tensor(0.1302, device='cuda:0')\n",
            "test intellectual_or_learning_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.7417, device='cuda:0')\n",
            "loss: tensor(0.0479, device='cuda:0')\n",
            "test psychiatric_or_mental_illness\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9619, device='cuda:0')\n",
            "loss: tensor(0.0092, device='cuda:0')\n",
            "test other_disability\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2846, device='cuda:0')\n",
            "Downloading: 100% 1.59k/1.59k [00:00<00:00, 8.01MB/s]\n",
            "Downloading: 100% 971M/971M [00:16<00:00, 60.2MB/s]\n",
            "Downloading: 100% 878k/878k [00:00<00:00, 17.7MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 8.99MB/s]\n",
            "Downloading: 100% 26.0/26.0 [00:00<00:00, 149kB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "train epoch:  0\n",
            "Batch_loss $1.5184:   2% 999/64822 [05:06<5:17:59,  3.35it/s]999\n",
            "It is false Christianity to preach and practice fear, loathing and rejection of gays.\n",
            "\n",
            "It is false to preach and practice fear, loathing and rejection of\n",
            "\n",
            "It is false theology to preach and practice fear, loathing and rejection of Jesus.\n",
            "Batch_loss $1.1013:   3% 1999/64822 [10:13<5:14:20,  3.33it/s]1999\n",
            "Love the Caveman DE!  Men are really a lot of trouble.\n",
            "\n",
            "Love theman DE! are really a lot of trouble\n",
            "\n",
            "Love the man DE! You are really a lot of trouble.\n",
            "Batch_loss $0.9564:   5% 2999/64822 [15:20<5:13:21,  3.29it/s]2999\n",
            "This has always confused me. It reminds me of the Nazis profiling Jews... obviously not a good thing.  How can we ever become a race-blind society if we continue to obsess over race?\n",
            "\n",
            "This has always confused It reminds of the profiling... obviously not a good thing  How can we ever become a- if we continue to obsess over\n",
            "\n",
            "This has always confused me. It reminds me of the FBI profiling Jews... obviously not a good thing.  How can we ever become a non-racist if we continue?\n",
            "Batch_loss $0.8801:   6% 3999/64822 [20:27<5:05:44,  3.32it/s]3999\n",
            "That's because I detect more than a whiff of Islamaphobia in the comments.\n",
            "\n",
            "That's because I detect more than a whiffaphobia in the comments\n",
            "\n",
            "That's because I detect more than a whiff of Islamaphobia in the comments.\n",
            "Batch_loss $0.8297:   8% 4999/64822 [25:34<5:09:36,  3.22it/s]4999\n",
            "\"Yea it's a racket till God forbid you get disabled and have to apply?\"--Whether Kelcy might need it in the future is irrelevant to the fact that the program is being defrauded today.\n",
            "\n",
            "\"Y it's a racket forbid and have to apply--Whether Kel might need it in the future is irrelevant to the fact that the is being defrauded today\n",
            "\n",
            "\"Yawn it's a racket. God forbid you and have to apply.\"--Whether Kelowne might need it in the future is irrelevant to the fact that the bank is being defrauded today.\n",
            "Batch_loss $0.7959:   9% 5999/64822 [30:40<4:40:36,  3.49it/s]5999\n",
            "He's continuing to declare war on facts.  He doesn't seem to like them so much....\n",
            "\n",
            "'s continuing to declare on facts doesn't seem to like them so much....\n",
            "\n",
            "Trump's continuing to declare war on facts.  He doesn't seem to like them so much....\n",
            "Batch_loss $0.7740:  11% 6999/64822 [35:46<4:57:36,  3.24it/s]6999\n",
            "So, Ayres and the murderous Weather Underground were actually conservatives?  Who knew....\n",
            "\n",
            "So, Ayres and the Weather were actually  Who knew....\n",
            "\n",
            "So, Ayres and the National Weather Service were actually predicting.  Who knew....\n",
            "Batch_loss $0.7532:  12% 7999/64822 [40:53<4:23:43,  3.59it/s]7999\n",
            "Every apostate blames the Church for his apostasy.\n",
            "\n",
            "Everyate blames the for his apostasy\n",
            "\n",
            "Every Catholic churchate blames the pope for his apostasy.\n",
            "Batch_loss $0.7366:  14% 8999/64822 [46:01<5:04:13,  3.06it/s]8999\n",
            "Depends - are you going to hold him accountable for his sexual attacks on women?\n",
            "\n",
            "Depends - are you going to hold him accountable for his attacks on\n",
            "\n",
            "Depends - are you going to hold him accountable for his sexual attacks on women\n",
            "Batch_loss $0.7242:  15% 9999/64822 [51:10<4:43:03,  3.23it/s]9999\n",
            "All I can say Maggie is keep going to that class.  I'll be looking for a complimentary article on the Trudeau liberals.\n",
            "\n",
            "All I can say is keep going to that  I'll be looking for a complimentary article on the\n",
            "\n",
            "All I can say is keep going to that.  I'll be looking for a complimentary article on the subject.\n",
            "Batch_loss $0.7127:  17% 10999/64822 [56:16<4:38:41,  3.22it/s]10999\n",
            "In what way?  E.g., how is this different than what Canada and the rest of the G7-, etc. have been saying about North Korea for years?    (I mean in contrast to Trump's bombast)\n",
            "\n",
            "In what way  E.g., how this different than what the rest of the G etc have been saying    (I mean in contrast to's bombast)\n",
            "\n",
            "In what way?  E.g., how is this different than what Trump and the rest of the G Party have been saying?    (I mean in contrast to Trump's bombast)\n",
            "Batch_loss $0.7034:  19% 11999/64822 [1:01:24<4:46:00,  3.08it/s]11999\n",
            "\"To much to hope for\"??  Not if you believe in the Easter Bunny, my man. Sarah's out there howlin' round the campfire with the best of them now.\n",
            "\n",
            "\"To much to hope for\"??  Not if believe in the, my's out there howlin' round the campfire with the best of them now\n",
            "\n",
            "\"To much to hope for\"??  Not if you believe in the Bible, my man's out there howlin' round the campfire with the best of them now.\n",
            "Batch_loss $0.6950:  20% 12999/64822 [1:06:31<4:24:28,  3.27it/s]12999\n",
            "Your a troll\n",
            "\n",
            "Your a\n",
            "\n",
            "Your a fool\n",
            "Batch_loss $0.6881:  22% 13999/64822 [1:11:37<4:01:19,  3.51it/s]13999\n",
            "\"Fake News!\" scream Black Knees\n",
            "\n",
            "\"Fake News!\" scream Knees\n",
            "\n",
            "\"Fake News!\" scream Black Knees\n",
            "Batch_loss $0.6818:  23% 14999/64822 [1:16:43<4:16:01,  3.24it/s]14999\n",
            "Are there? Please cite the news story, evidence or research that has identified these women.\n",
            "\n",
            "Are there? Please cite the news story, evidence or research that has these\n",
            "\n",
            "Are there? Please cite the news story, evidence or research that has supported these women.\n",
            "Batch_loss $0.6760:  25% 15999/64822 [1:21:50<4:13:35,  3.21it/s]15999\n",
            "Gee thanks Rhonda for your helpful insights. Nobody else could have possible thought of that. Perhaps if you had presented a detailed plan on how to deal with a 7-year old in the WH, that might have actually helped but thanks for showing up anyway. Here is your cracker.\n",
            "\n",
            "G thanks for helpful insights Nobody else could have possible thought of that Perhaps if had presented a how to in the WH, that might have actually helped but thanks for showing up anyway Here is your cracker\n",
            "\n",
            "Greetings and thanks for your helpful insights. Nobody else could have possible thought of that. Perhaps if he had presented a lesson on how to work in the WH, that might have actually helped but thanks for showing up anyway. Here is your cracker.\n",
            "Batch_loss $0.6708:  26% 16999/64822 [1:26:56<3:57:42,  3.35it/s]16999\n",
            "Tell that to the people of Burlington, ON. Even higher elevation areas can have flooding via sewer backup, insufficient drainage from the soil or excessive rain.\n",
            "\n",
            "Tell that to the, ON Even higher elevation areas can have flooding via backup, insufficient drainage from the soil excessive\n",
            "\n",
            "Tell that to the river, ON HILL. Even higher elevation areas can have flooding via water backup, insufficient drainage from the soil and excessive evaporation.\n",
            "Batch_loss $0.6663:  28% 17999/64822 [1:32:04<4:02:42,  3.22it/s]17999\n",
            "Privileged ya think? There are plenty of nut cases that are rotting in prisons for far less crimes.\n",
            "\n",
            "Priv ya think There are plenty of that are rotting in prisons far less\n",
            "\n",
            "Privilege ya think. There are plenty of people that are rotting in prisons with far less.\n",
            "Batch_loss $0.6622:  29% 18999/64822 [1:37:11<3:53:08,  3.28it/s]18999\n",
            "yeah, me too. I gave up on church a log time ago. Too many phonies for me. People using church as a social club, a dating service.  Pastors in on the scam too.\n",
            "\n",
            "yeah, too I gave up on a log time ago Too many for People using as a social club, a service in on the scam too\n",
            "\n",
            "yeah, me too. I gave up on Christianity a log time ago. Too many people for me. People using religion as a social club, a church service.  I'm in on the scam too.\n",
            "Batch_loss $0.6586:  31% 19999/64822 [1:42:18<3:58:29,  3.13it/s]19999\n",
            "You are the snowflake.  My point is that the media is so obsessed with Trump that they totally ignore other important issues.\n",
            "\n",
            "You are the snow  My point is that the is so obsessed that they totally ignore other important issues\n",
            "\n",
            "You are the snowflake.  My point is that the media is so obsessed with Trump that they totally ignore other important issues.\n",
            "Batch_loss $0.6554:  32% 20999/64822 [1:47:23<3:45:32,  3.24it/s]20999\n",
            "Reminds me of that great line from \"The Blues Brothers\" when the band winds up performing at Bob's Country Bunker and the barmaid tells Elwood, \"Oh, we like both kinds of music, country AND western!\"\n",
            "\n",
            "Reminds me of that great line from \"The\" when the band winds up performing at Bob's Country Bunker and thearm tells El, \"Oh, we like both kinds music, AND!\"\n",
            "\n",
            "Reminds me of that great line from \"The Rocky Mountain Show\" when the band winds up performing at Bob's Country Bunker and the drumarmy tells El Paso, \"Oh, we like both kinds of music, country AND country!\"\n",
            "Batch_loss $0.6516:  34% 21999/64822 [1:52:31<3:24:53,  3.48it/s]21999\n",
            "The fact that the deep state is being named and discussed at all is a sign of its unprecedented vulnerability.\n",
            "\n",
            "The fact that is being and discussed at all is a sign of unprecedented\n",
            "\n",
            "The fact that Trump is being mentioned and discussed at all is a sign of his unprecedented incompetence.\n",
            "Batch_loss $0.6489:  35% 22999/64822 [1:57:38<3:34:02,  3.26it/s]22999\n",
            "Not a done deal.  Since the house bill is different from what the senate passed, it'll most likely go to conference committee.\n",
            "\n",
            "Not a done deal  Since the bill is different from what the passed, it'll most likely go to conference committee\n",
            "\n",
            "Not a done deal.  Since the House bill is different from what the Senate passed, it'll most likely go to conference committee.\n",
            "Batch_loss $0.6458:  37% 23999/64822 [2:02:45<3:14:58,  3.49it/s]23999\n",
            "It won't be the end of a Jewish majority as at present the Jewish birthrate is trending upwards while the Arab birthrate is descending.\n",
            "\n",
            "It't be the end of a majority as at present the birthrate is trending upwards while the birthrate is\n",
            "\n",
            "It won't be the end of a Jewish majority as at present the Jewish birthrate is trending upwards while the white Christian birth rate is declining.\n",
            "Batch_loss $0.6438:  39% 24999/64822 [2:07:51<3:28:49,  3.18it/s]24999\n",
            "Roy thanks you Barabara 😉\n",
            "\n",
            "Roy thanks you Barab ðŁĺī\n",
            "\n",
            "Roy thanks you Barabah. 😂\n",
            "Batch_loss $0.6412:  40% 25999/64822 [2:12:56<3:27:09,  3.12it/s]25999\n",
            "While you're at it can you please also tell us who wins the World Series and The Super Bowl?\n",
            "\n",
            "While you're at it you please also tell us who the and?\n",
            "\n",
            "While you're at it - will you please also tell us who won the election and why?\n",
            "Batch_loss $0.6394:  41% 26811/64822 [2:17:05<3:23:01,  3.12it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PF_-Af-B4dN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train the transfer pipeline and generate pairs using style transfer and word replacement.**\n",
        "###Results are found in folders Code/generations.\n",
        "######Note: Generating modified comments for all original comments in the dataset can take a long time.\n"
      ],
      "metadata": {
        "id": "rvcBw6OL0vWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!chmod +x Tables.sh"
      ],
      "metadata": {
        "id": "kFJYZkkr26EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!./Tables.sh"
      ],
      "metadata": {
        "id": "6wmlzx4A7Y3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cLOLgQsZ4OkV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}