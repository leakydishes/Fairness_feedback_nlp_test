Deakin University Internship 2023


This research reproduces and tests the fair classification for Natural Language Processing (NLP) tasks (Human-Guided Fair Classification for Natural Language Processing, 2023). Using unsupervised style transfer to generate pairs of sentences that are similar in meaning but differ along sensitive attributes. The model is then validated with human feedback to ensure that the generated pairs adhere to fair constraints (treated equally). The resulting pairs are used to train toxicity classifiers, which aim to mitigate biases and ensure equitable outcomes in NLP tasks.


Project includes,
Phase 1, Human-Guided Fair Classification for NLP
Phase 2, Semantic Communication


Reference:
ICLR (International Conference on Learning Representations) 2023 paper "Human-Guided Fair Classification for Natural Language Processing." 

*@inproceedings{
dorner2023humanguided,
title={Human-Guided Fair Classification for Natural Language Processing},
author={Florian E. Dorner and Momchil Peychev and Nikola Konstantinov and Naman Goel and Elliott Ash and Martin Vechev},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=N_g8TT9Cy7f}
}*
