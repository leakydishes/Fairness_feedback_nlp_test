{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1jixwOITC2bjIzZRc388tdtr1wOYlxE2f",
      "authorship_tag": "ABX9TyP94vrkQ6+yQBFo7zpzgHYo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leakydishes/Fairness_feedback_nlp_test/blob/main/Fairness_feedback_nlp_test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Deakin University Internship 2023**\n",
        "##Human-Guided Fair Classification for NLP\n",
        "#####Te' Claire\n",
        "\n",
        "*@inproceedings{\n",
        "dorner2023humanguided,\n",
        "title={Human-Guided Fair Classification for Natural Language Processing},\n",
        "author={Florian E. Dorner and Momchil Peychev and Nikola Konstantinov and Naman Goel and Elliott Ash and Martin Vechev},\n",
        "booktitle={The Eleventh International Conference on Learning Representations },\n",
        "year={2023},\n",
        "url={https://openreview.net/forum?id=N_g8TT9Cy7f}\n",
        "}*"
      ],
      "metadata": {
        "id": "1krF2sLeA9Ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 1. Mount Google Drive**"
      ],
      "metadata": {
        "id": "rnMkrDpv5XY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuts1xQ2_yPd",
        "outputId": "c02345b4-cf9a-456e-a34e-b087a77b1b87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 2.Download the train.csv file from the Civil comments dataset to Code/Datasets/Kaggle_Toxicity**\n",
        "####Set up a virtual environment with the required packages"
      ],
      "metadata": {
        "id": "riJuKYPvAzPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Note: Google Colab already has Python pre-installed therefore you don't need to create a virtual environment. Instead install dependencies."
      ],
      "metadata": {
        "id": "gg9i_BeQoFoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/fairness-feedback-nlp-master/Code"
      ],
      "metadata": {
        "id": "2FKZmY_S5tzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd4156c-fb4d-4038-eee3-09de992575f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/fairness-feedback-nlp-master/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Install python 3.8 and update"
      ],
      "metadata": {
        "id": "Tu6ZHHic10Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install python3.8\n",
        "!python3.8 -m ensurepip --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfnHxFukotDq",
        "outputId": "7581385f-d990-49e0-98dd-10e9124233d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [108 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,230 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,088 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [969 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [848 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [802 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [35.7 kB]\n",
            "Fetched 5,337 kB in 2s (2,369 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support python3.8\n",
            "  python3.8-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 5,099 kB of archives.\n",
            "After this operation, 18.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.17-1+jammy1 [793 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.17-1+jammy1 [2,023 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.17-1+jammy1 [1,817 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.17-1+jammy1 [438 kB]\n",
            "Fetched 5,099 kB in 4s (1,357 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 120493 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.8-minimal_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../1-python3.8-minimal_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.8-stdlib_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../5-python3.8_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.17-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-minimal (3.8.17-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.17-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "/usr/bin/python3.8: No module named ensurepip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list python versions\n",
        "!ls /usr/bin/python*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMHuy1OAo9LZ",
        "outputId": "ed73875c-4324-4d8d-c9f0-45ce7151ecf3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3     /usr/bin/python3.10-config  /usr/bin/python3-config\n",
            "/usr/bin/python3.10  /usr/bin/python3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#update python version\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1"
      ],
      "metadata": {
        "id": "Bm-ZnUMYqZUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b93f2140-3aa3-459f-a40b-6d6c662983c8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confirgure python version\n",
        "!sudo update-alternatives --config python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVGh3s64tzNV",
        "outputId": "1325139b-cf01-4e41-84d4-9679b5c1a0c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is only one alternative in link group python3 (providing /usr/bin/python3): /usr/bin/python3.8\n",
            "Nothing to configure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#permanently install the specific version to the google colab\n",
        "!sudo apt install python3-pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV2U9wrSt-DG",
        "outputId": "438c07bf-1511-40e4-ccec-876a75606a32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,965 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.3 [1,305 kB]\n",
            "Fetched 1,677 kB in 0s (5,282 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 121144 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.3_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Check correct packages installed for distutils and Numpy"
      ],
      "metadata": {
        "id": "rY-Jb9V52SwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python3.8-distutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30gzRE2nuaLv",
        "outputId": "30ba47ee-25c7-4f4d-e7ff-fb5ad576cc7d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.8-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.8-distutils python3.8-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 319 kB of archives.\n",
            "After this operation, 1,237 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.17-1+jammy1 [126 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.17-1+jammy1 [193 kB]\n",
            "Fetched 319 kB in 1s (240 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "(Reading database ... 122006 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.8-lib2to3_3.8.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../python3.8-distutils_3.8.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.17-1+jammy1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t1kEDf8K2Y_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall numpy==1.22.3\n",
        "#Check numpy version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UojJU7W0vZLC",
        "outputId": "a0769528-39aa-4f32-a222-9886ad25336e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.22.3\n",
            "  Downloading numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "Successfully installed numpy-1.22.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Then, run"
      ],
      "metadata": {
        "id": "44Ju1GkUp0mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tpaYQnTPt8e0",
        "outputId": "f09b740b-1658-4b7b-b213-61ec74439f3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.22.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (1.22.3)\n",
            "Collecting torch==1.11.0\n",
            "  Downloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.0\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.18.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.4.2\n",
            "  Downloading pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.6.3\n",
            "  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m736.6/736.6 KB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 KB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2023.6.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 KB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 KB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 KB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec\n",
            "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas==1.4.2->-r requirements.txt (line 5)) (1.16.0)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click\n",
            "  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib\n",
            "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 KB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=09ba65c60a7cd488bb29b9e26f603f247cdfcf0e3853b8db1b7af0e6bc1b2523\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, pytz, urllib3, typing-extensions, tqdm, scipy, regex, pyyaml, python-dateutil, packaging, joblib, idna, fsspec, filelock, click, charset-normalizer, certifi, torch, sacremoses, requests, pandas, huggingface-hub, transformers\n",
            "Successfully installed certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.6 filelock-3.12.2 fsspec-2023.6.0 huggingface-hub-0.16.4 idna-3.4 joblib-1.3.1 packaging-23.1 pandas-1.4.2 python-dateutil-2.8.2 pytz-2023.3 pyyaml-6.0.1 regex-2023.6.3 requests-2.31.0 sacremoses-0.0.53 scipy-1.6.3 tokenizers-0.12.1 torch-1.11.0 tqdm-4.64.0 transformers-4.18.0 typing-extensions-4.7.1 urllib3-2.0.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Check file path and script is granted permission to be executed as a program"
      ],
      "metadata": {
        "id": "lvyV7KCj2jOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/fairness-feedback-nlp-master/Code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMGoUHhtuexa",
        "outputId": "6cdbd9d1-4f71-4dfb-9e9d-5cb0a7cf89b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/fairness-feedback-nlp-master/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!chmod +x Generation.sh\n",
        "!chmod +x Generation_Quick.sh"
      ],
      "metadata": {
        "id": "mIXm04nczVm4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Additionally added Transfers"
      ],
      "metadata": {
        "id": "-b3ZSQ4S2y1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdVfDb6T0Z-5",
        "outputId": "245a1e07-84c7-4faf-d2ca-d2bc64171448"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.1.6)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "#### Add a click function in console to stop Google Collab from timing out\n",
        "#### NOTE: This does not work as google only gives 90min time on free plan, capcha box will appear and clicker no longer works as of 2023\n",
        "\n",
        "#### Declare function\n",
        "function ConnectButton() {\n",
        "    console.log(\"Working\");\n",
        "    document.querySelector(\"colab-toolbar-button\").click();\n",
        "}\n",
        "\n",
        "#### Define Function\n",
        "var connect = setInterval(ConnectButton, 100);\n",
        "\n",
        "\n",
        "#### stop\n",
        "clearInterval(connect)\n",
        "\n",
        "#### call back\n",
        "#### Define Function\n",
        "var connect = setInterval(ConnectButton, 100);\n"
      ],
      "metadata": {
        "id": "XD4oDLY34Vpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the code\n",
        "!./Generation_Quick.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBtK7CP3z0nk",
        "outputId": "eebb25d6-bcc1-4d1c-c410-97056365dd8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100% 481/481 [00:00<00:00, 2.55MB/s]\n",
            "Downloading: 100% 478M/478M [00:09<00:00, 54.8MB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Downloading: 100% 878k/878k [00:00<00:00, 3.21MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 4.81MB/s]\n",
            "216073\n",
            "21607\n",
            "epoch:  0\n",
            "Batch_loss $25.6238: 100% 12155/12155 [44:11<00:00,  4.58it/s]\n",
            "epoch:  1\n",
            "Batch_loss $33.5369: 100% 12155/12155 [44:28<00:00,  4.56it/s]\n",
            "epoch:  2\n",
            "Batch_loss $21.6609: 100% 12155/12155 [44:23<00:00,  4.56it/s]\n",
            "Testing on train\n",
            "100% 12155/12155 [12:22<00:00, 16.38it/s]\n",
            "train male\n",
            "tpr: tensor(0.9977, device='cuda:0')\n",
            "tnr: tensor(0.9486, device='cuda:0')\n",
            "loss: tensor(0.0138, device='cuda:0')\n",
            "train female\n",
            "tpr: tensor(0.9992, device='cuda:0')\n",
            "tnr: tensor(0.9423, device='cuda:0')\n",
            "loss: tensor(0.0093, device='cuda:0')\n",
            "train transgender\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9871, device='cuda:0')\n",
            "loss: tensor(0.0069, device='cuda:0')\n",
            "train other_gender\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2918, device='cuda:0')\n",
            "train heterosexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9771, device='cuda:0')\n",
            "loss: tensor(0.0075, device='cuda:0')\n",
            "train homosexual_gay_or_lesbian\n",
            "tpr: tensor(0.9973, device='cuda:0')\n",
            "tnr: tensor(0.9931, device='cuda:0')\n",
            "loss: tensor(0.0031, device='cuda:0')\n",
            "train bisexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9052, device='cuda:0')\n",
            "loss: tensor(0.0279, device='cuda:0')\n",
            "train other_sexual_orientation\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.3091, device='cuda:0')\n",
            "train christian\n",
            "tpr: tensor(0.9985, device='cuda:0')\n",
            "tnr: tensor(0.9438, device='cuda:0')\n",
            "loss: tensor(0.0090, device='cuda:0')\n",
            "train jewish\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9910, device='cuda:0')\n",
            "loss: tensor(0.0033, device='cuda:0')\n",
            "train muslim\n",
            "tpr: tensor(0.9997, device='cuda:0')\n",
            "tnr: tensor(0.9864, device='cuda:0')\n",
            "loss: tensor(0.0036, device='cuda:0')\n",
            "train hindu\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9874, device='cuda:0')\n",
            "loss: tensor(0.0125, device='cuda:0')\n",
            "train buddhist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9901, device='cuda:0')\n",
            "loss: tensor(0.0116, device='cuda:0')\n",
            "train atheist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9980, device='cuda:0')\n",
            "loss: tensor(0.0057, device='cuda:0')\n",
            "train other_religion\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.0017, device='cuda:0')\n",
            "loss: tensor(0.1277, device='cuda:0')\n",
            "train black\n",
            "tpr: tensor(0.9993, device='cuda:0')\n",
            "tnr: tensor(0.9909, device='cuda:0')\n",
            "loss: tensor(0.0035, device='cuda:0')\n",
            "train white\n",
            "tpr: tensor(0.9992, device='cuda:0')\n",
            "tnr: tensor(0.9902, device='cuda:0')\n",
            "loss: tensor(0.0038, device='cuda:0')\n",
            "train asian\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9819, device='cuda:0')\n",
            "loss: tensor(0.0062, device='cuda:0')\n",
            "train latino\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9712, device='cuda:0')\n",
            "loss: tensor(0.0181, device='cuda:0')\n",
            "train other_race_or_ethnicity\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.1556, device='cuda:0')\n",
            "loss: tensor(0.1001, device='cuda:0')\n",
            "train physical_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.1495, device='cuda:0')\n",
            "loss: tensor(0.0913, device='cuda:0')\n",
            "train intellectual_or_learning_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.6743, device='cuda:0')\n",
            "loss: tensor(0.0499, device='cuda:0')\n",
            "train psychiatric_or_mental_illness\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9756, device='cuda:0')\n",
            "loss: tensor(0.0074, device='cuda:0')\n",
            "train other_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(6.6850e-05, device='cuda:0')\n",
            "loss: tensor(0.2565, device='cuda:0')\n",
            "Testing on test\n",
            "100% 1351/1351 [01:22<00:00, 16.32it/s]\n",
            "test male\n",
            "tpr: tensor(0.9988, device='cuda:0')\n",
            "tnr: tensor(0.9458, device='cuda:0')\n",
            "loss: tensor(0.0141, device='cuda:0')\n",
            "test female\n",
            "tpr: tensor(0.9989, device='cuda:0')\n",
            "tnr: tensor(0.9439, device='cuda:0')\n",
            "loss: tensor(0.0092, device='cuda:0')\n",
            "test transgender\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9862, device='cuda:0')\n",
            "loss: tensor(0.0070, device='cuda:0')\n",
            "test other_gender\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2919, device='cuda:0')\n",
            "test heterosexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9746, device='cuda:0')\n",
            "loss: tensor(0.0075, device='cuda:0')\n",
            "test homosexual_gay_or_lesbian\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9929, device='cuda:0')\n",
            "loss: tensor(0.0029, device='cuda:0')\n",
            "test bisexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9055, device='cuda:0')\n",
            "loss: tensor(0.0280, device='cuda:0')\n",
            "test other_sexual_orientation\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.3090, device='cuda:0')\n",
            "test christian\n",
            "tpr: tensor(0.9971, device='cuda:0')\n",
            "tnr: tensor(0.9433, device='cuda:0')\n",
            "loss: tensor(0.0093, device='cuda:0')\n",
            "test jewish\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9913, device='cuda:0')\n",
            "loss: tensor(0.0033, device='cuda:0')\n",
            "test muslim\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9871, device='cuda:0')\n",
            "loss: tensor(0.0034, device='cuda:0')\n",
            "test hindu\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9865, device='cuda:0')\n",
            "loss: tensor(0.0125, device='cuda:0')\n",
            "test buddhist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9901, device='cuda:0')\n",
            "loss: tensor(0.0117, device='cuda:0')\n",
            "test atheist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9980, device='cuda:0')\n",
            "loss: tensor(0.0057, device='cuda:0')\n",
            "test other_religion\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.0017, device='cuda:0')\n",
            "loss: tensor(0.1277, device='cuda:0')\n",
            "test black\n",
            "tpr: tensor(0.9957, device='cuda:0')\n",
            "tnr: tensor(0.9914, device='cuda:0')\n",
            "loss: tensor(0.0037, device='cuda:0')\n",
            "test white\n",
            "tpr: tensor(0.9989, device='cuda:0')\n",
            "tnr: tensor(0.9902, device='cuda:0')\n",
            "loss: tensor(0.0037, device='cuda:0')\n",
            "test asian\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9812, device='cuda:0')\n",
            "loss: tensor(0.0064, device='cuda:0')\n",
            "test latino\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9711, device='cuda:0')\n",
            "loss: tensor(0.0182, device='cuda:0')\n",
            "test other_race_or_ethnicity\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.1550, device='cuda:0')\n",
            "loss: tensor(0.1004, device='cuda:0')\n",
            "test physical_disability\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0.1463, device='cuda:0')\n",
            "loss: tensor(0.0917, device='cuda:0')\n",
            "test intellectual_or_learning_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.6754, device='cuda:0')\n",
            "loss: tensor(0.0497, device='cuda:0')\n",
            "test psychiatric_or_mental_illness\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9766, device='cuda:0')\n",
            "loss: tensor(0.0074, device='cuda:0')\n",
            "test other_disability\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2563, device='cuda:0')\n",
            "Downloading: 100% 1.59k/1.59k [00:00<00:00, 8.18MB/s]\n",
            "Downloading: 100% 971M/971M [00:19<00:00, 53.0MB/s]\n",
            "Downloading: 100% 878k/878k [00:00<00:00, 9.12MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 5.75MB/s]\n",
            "Downloading: 100% 26.0/26.0 [00:00<00:00, 153kB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "train epoch:  0\n",
            "Batch_loss $1.5389:   2% 999/64822 [05:10<5:17:49,  3.35it/s]999\n",
            "You have to get to the 4th candidate before you find one not born in the 1940's\n",
            "\n",
            "You have to get to the 4th candidate before you find in the's\n",
            "\n",
            "You have to get to the 4th candidate before you find yourself in the middle.\n",
            "Batch_loss $1.1574:   3% 1999/64822 [10:20<5:42:55,  3.05it/s]1999\n",
            "Then why all the hysteria?\n",
            "\n",
            "Then why all the?\n",
            "\n",
            "Then why all the guns?\n",
            "Batch_loss $1.0354:   5% 2999/64822 [15:28<5:44:16,  2.99it/s]2999\n",
            "So she would like to be president of SA. Can she at least use co.za instead of.com!  PROUDLY SOUTH AFRICAN. Not white monopoly capital.com :)\n",
            "\n",
            "So would like to be president. Can she at least use co.za instead of.com! PROUDLY. Not monopoly.com :)\n",
            "\n",
            "So she would like to be president. Can she at least use co.za instead of.com!  PROUDLY WHITE. Not white monopoly .com :)\n",
            "Batch_loss $0.9618:   6% 3999/64822 [20:39<5:03:26,  3.34it/s]3999\n",
            "\"Bayard De Volo is the chair and associate professor of Women and Gender Studies.\"  Translation: Neo-Marxist radical nutjob.\n",
            "\n",
            "\"Bayard De Volo is the chair and associate professor of and Studies.\" Translation:- radical nutjob.\n",
            "\n",
            "\"Bayard De Volo is the chair and associate professor of sociology and Gender Studies.\"  Translation:  Anti-Semitism radical nutjob.\n",
            "Batch_loss $0.9161:   8% 4999/64822 [25:49<4:55:45,  3.37it/s]4999\n",
            "Their \"undemocratic 'electoral college' system\" is no less fair than our 1st past the post system.  Also Obama is not only making it harder for Trump but also for the American people, being a typical politician of course he doesn't give a toss about that.\n",
            "\n",
            "undemelectoral' system\" is less than 1st past the post system. Also is not only making it harder for but also for, being a typical politician of course doesn't give a toss about that.\n",
            "\n",
            "\"undemocratic' system\" is much less democratic than our 1st past the post system.  Also he is not only making it harder for him but also for him, being a typical politician of course he doesn't give a toss about that.\n",
            "Batch_loss $0.8835:   9% 5999/64822 [30:58<5:04:54,  3.22it/s]5999\n",
            "Timothy Sloan is just another white collar criminal supported by the thieves in the house and senate, The head thief is our President.\n",
            "\n",
            "Timothy Sloan is just another collar supported by the in the house and, The head thief is our.\n",
            "\n",
            "Timothy Sloan is just another white collar criminal supported by the people in the house and outside, The head thief is our president.\n",
            "Batch_loss $0.8618:  11% 6999/64822 [36:07<4:58:09,  3.23it/s]6999\n",
            ";)\n",
            "\n",
            ")\n",
            "\n",
            "(C)\n",
            "Batch_loss $0.8428:  12% 7999/64822 [41:17<4:48:31,  3.28it/s]7999\n",
            "Eastern block had a lot of jobs in public sector.  See where it got them.\n",
            "\n",
            " block had a lot of in sector.  See where it got them.\n",
            "\n",
            "I guess this block had a lot of people in the private sector.  See where it got them.\n",
            "Batch_loss $0.8286:  14% 8999/64822 [46:26<4:57:28,  3.13it/s]8999\n",
            "Has anyone informed Trump about the GM Cami plant in Ontario Canada that is starting production on the new model Equinox, Terrain... vehicles.....3000 jobs right there..\n",
            "\n",
            "Has anyone informed Trump about the in that is starting production on the new modelin, Terrain... vehicles.....3000 right there..\n",
            "\n",
            "Has anyone informed Trump about the company in Canada that is starting production on the new model 4x4, Terrain... vehicles.....3000 jobs right there..\n",
            "Batch_loss $0.8211:  15% 9999/64822 [51:35<4:59:00,  3.06it/s]9999\n",
            "The British press covered the white supremacists  march much more thoroughly than any 'western' paper with more photos and more details. Those details are being shared today so companies who have hired those thugs, can fire them as they do not represent what any company wants in an employee.\n",
            "\n",
            "The covered the much more thoroughly than any '' paper with more photos and more details. Those details are being shared today so who have hired those, can fire them as they do not represent what any wants in an employee.\n",
            "\n",
            "The Globe covered the story much more thoroughly than any 'local' paper with more photos and more details. Those details are being shared today so those who have hired those people, can fire them as they do not represent what any employer wants in an employee.\n",
            "Batch_loss $0.8110:  17% 10999/64822 [56:43<4:30:42,  3.31it/s]10999\n",
            "If you pay attention, you will see that crime is down from historical levels. Now you just want to spend more tax money, to what end?\n",
            "\n",
            "If you pay attention, you will see that is levels. you just want to spend more tax money, to what end?\n",
            "\n",
            "If you pay attention, you will see that the budget deficit is below levels.  Do you just want to spend more tax money, to what end?\n",
            "Batch_loss $0.8019:  19% 11999/64822 [1:01:52<4:36:59,  3.18it/s]11999\n",
            "You didn't think that PM El Smarmo would play it straight, did you?  Oh, how naive.  He's Justin and you're not.  Now shaddup.\n",
            "\n",
            "You didn't think that PM Smarmo would play it, you?  Oh, how naive.'s and you're not. Now shaddup.\n",
            "\n",
            "You didn't think that PM John Smarmo would play it cool, were you?  Oh, how naive.  He's a man and you're not.  Now shaddup.\n",
            "Batch_loss $0.7940:  20% 12999/64822 [1:07:03<4:20:58,  3.31it/s]12999\n",
            "Once agin Mr. Kelly is blaming low oil prices for the $2 billion he gave back to the richest corporations in the history of the earth. Man the $2 billion would look good in a savings account right now.\n",
            "\n",
            "Once agin. Kelly is blaming for the $ billion gave back the in the history of the earth. the $2 billion look good in a savings account right now.\n",
            "\n",
            "Once agin Mr. Kelly is blaming the man for the $2 billion he gave back to the richest man in the history of the earth.    Maybe  the $ 2 billion would look good in a savings account right now.\n",
            "Batch_loss $0.7852:  22% 13999/64822 [1:12:13<4:07:50,  3.42it/s]13999\n",
            "You seem to be having a hard time following this thread.\n",
            "\n",
            " to be having a time this.\n",
            "\n",
            "They seem to be having a great time in this one.\n",
            "Batch_loss $0.7788:  23% 14999/64822 [1:17:22<4:15:55,  3.24it/s]14999\n",
            "Do you think the NCAA is clean? By some accounts the NCAA is actually worse. Also, Bishop finished behind TWO men because if anyone thinks Margaret Wambui is a woman they need their eyes checking!\n",
            "\n",
            "Do you think the is? By some accounts the is actually worse. Also, finished behind TWO because if anyone thinks Margaret Wambui is they need their eyes checking!\n",
            "\n",
            "Do you think the race is close? By some accounts the competition is actually worse. Also, they finished behind TWO women because if anyone thinks Margaret Wambui is fair they need their eyes checking!\n",
            "Batch_loss $0.7730:  25% 15999/64822 [1:22:30<4:10:54,  3.24it/s]15999\n",
            "Essential government services have no business being outsourced to the lowest bidder. Something can and should be outsourced, others clearly should not.\n",
            "\n",
            "ential have being to the lowest bidder. can should be outs, others should not.\n",
            "\n",
            "I have no business being sold to the lowest bidder. Some people can or should be outsized, others just should not.\n",
            "Batch_loss $0.7679:  26% 16999/64822 [1:27:40<4:06:26,  3.23it/s]16999\n",
            "Smart commentary.  Thanks.\n",
            "\n",
            ".  Thanks.\n",
            "\n",
            "Good.  Thanks.\n",
            "Batch_loss $0.7634:  28% 17999/64822 [1:32:48<4:08:37,  3.14it/s]17999\n",
            "\"SAD is a loaded word Trump uses. What is the root message?\" -- SkeptiCat  Irony.\n",
            "\n",
            "\" is a loaded word uses. is the root message?\" -- SkeptiCaty.\n",
            "\n",
            "\"Manly is a loaded word man uses. What is the root message?\" -- SkeptiCat Many.\n",
            "Batch_loss $0.7590:  29% 18999/64822 [1:37:57<3:44:24,  3.40it/s]18999\n",
            "\"In a sane and sensible city, authorities at all levels would be pulling together (...)\" For me it seems that they are pulling together... in different directions\n",
            "\n",
            "\"In a and, at all levels be pulling together (...)\" For me it seems that they are pulling together... in different directions\n",
            "\n",
            "\"In a country and world, people at all levels should be pulling together (...)\" For me it seems that they are pulling together... in different directions\n",
            "Batch_loss $0.7546:  31% 19999/64822 [1:43:05<3:37:13,  3.44it/s]19999\n",
            "Where are all the white Christians, denouncing their activities? Where are the protests?\n",
            "\n",
            "Where are all the, denouncing their activities? Where are the?\n",
            "\n",
            "Where are all the white supremacists, denouncing their activities? Where are the Nazis?\n",
            "Batch_loss $0.7504:  32% 20999/64822 [1:48:13<3:25:51,  3.55it/s]20999\n",
            "The more garbage they add to the vehicles the more problems they create. They can't control the recalls now.\n",
            "\n",
            "The more add the the more problems they create. can control the.\n",
            "\n",
            "The more people add to the economy the more problems they create. They can't control the economy.\n",
            "Batch_loss $0.7471:  34% 21999/64822 [1:53:20<3:23:37,  3.51it/s]21999\n",
            "my sincere apologies for butting into what was,  i guess,  a private conversation....\n",
            "\n",
            " sincere forting into what was,  i,  a conversation....\n",
            "\n",
            "Very sincere apology for blunderting into what was,  i guess,  a civil conversation....\n",
            "Batch_loss $0.7439:  35% 22999/64822 [1:58:27<3:23:07,  3.43it/s]22999\n",
            "Re:RSouthward When in the voting booth I don't usually think of  % and numbers. But I did remember a $90,000 cheque in 2015.\n",
            "\n",
            ": When in the I don't usually of and. But I did remember a $000 cheque in 2015.\n",
            "\n",
            "Correct:  When in the office I don't usually think of my wife and I. But I did remember a $100,000 cheque in 2015.\n",
            "Batch_loss $0.7406:  37% 23999/64822 [2:03:38<3:36:41,  3.14it/s]23999\n",
            "Actually, Trudeau's honeymoon period breaks the record. It's only natural that a government's, or prime minister's, popularity fades over time. It's the Opposition's job to bring a popular politician down to earth. We'll find out in three years how Canadians really feel about Mr. Trudeau.\n",
            "\n",
            "Actually, Trudeau'smoon period breaks the record. It's only natural that a government's prime minister's, popularity fades over time. It's the Opposition's job to bring a politician down to earth. We find out in three years how really feel about. Trudeau.\n",
            "\n",
            "Actually, Trudeau's honeymoon period breaks the record. It's only natural that a government's leader's, especially a prime minister's, popularity fades over time. It is the Opposition's job to bring a politician down to earth. We'll find out in three years how Canadians really feel about Mr.\n",
            "Batch_loss $0.7374:  39% 24999/64822 [2:08:50<3:15:58,  3.39it/s]24999\n",
            "Does the product have to be in glass jars? Can the container be plastic? If yes, they could easily be injection-molded in Canada and quickly cranked out on demand.\n",
            "\n",
            "Does the product have to be jars? Can the container be? If yes, they easily be injection-molded and quickly cranked out on demand.\n",
            "\n",
            "Does the product have to be plastic jars? Can the container be plastic? If yes, they could easily be injection-molded plastic and quickly cranked out on demand.\n",
            "Batch_loss $0.7348:  40% 25999/64822 [2:13:59<3:41:40,  2.92it/s]25999\n",
            "\"Social media users quickly took notice of the wording and responded with memes to express disbelief at Yamaguchi’s words\" SA/AP/MSM forgot to insert....\"Social media users..aka SNOWFLAKES....quickly took notice blah blah blah......\"\n",
            "\n",
            "\"Social media users quickly took notice of the wording and responded with memes to express atâĢs words\" SA/AP/M forgot to insert....Social media users..aka SNFLES....quickly took notice blah blah blah......\"\n",
            "\n",
            "\"Social media users quickly took notice of the wording and responded with memes to express their shock at Trump’s words\" SA/AP/MAGA forgot to insert.... Social media victims..aka SNICKFLAKES....quickly took notice blah blah blah......\"\n",
            "Batch_loss $0.7322:  42% 26999/64822 [2:19:09<3:14:13,  3.25it/s]26999\n",
            "Two days ago I got on the elevator with a woman in a Niqab, with three little children in tow. I said hello, she said hello, and we both rode the elevator to the ground floor and got out. Whew, dodged THAT bullet!  Posted by S. MacDonald\n",
            "\n",
            "Two days ago got the with with in tow. I said hello, said hello, and we both rode the elevator to the ground floor and out. Whew, THAT! Posted by S. MacDonald\n",
            "\n",
            "Two days ago I got out of the car with a woman with two children in tow. I said hello, she said hello and we both rode the elevator to the ground floor and came out. Whew,  THAT was funny!   Posted by S. MacDonald\n",
            "Batch_loss $0.7295:  43% 27999/64822 [2:24:20<3:06:06,  3.30it/s]27999\n",
            ">>Hyuck. >>Got any other knee slappers?. Yep, here is another one:. \"Trudeau and The Middle Class\"  - in the same sentence.\n",
            "\n",
            ">>Hyuck. >>Got any?. Yep, here is another one: \"Tr and\" - in the same sentence.\n",
            "\n",
            ">>Hyuck. >>Got any ideas?. Yep, here is another one:  \"Trudeau and Trump\"  - in the same sentence.\n",
            "Batch_loss $0.7273:  45% 28999/64822 [2:29:30<3:05:24,  3.22it/s]28999\n",
            "On the contrary!  Catholic right-wingers have consistently been heard and seen to complain that This Pope should not be speaking extemporaneously, or be covered by the press!  Censorship, by another name!\n",
            "\n",
            "On the contrary!- consistently been heard and seen to complain that This should not be extemporaneously, or be covered by the! Censorship, by another name!\n",
            "\n",
            "On the contrary! Anti-Christians have consistently been heard and seen to complain that This Church should not be censored extemporaneously, or be covered by the media!  Censorship, by another name!\n",
            "Batch_loss $0.7254:  46% 29999/64822 [2:34:39<3:09:53,  3.06it/s]29999\n",
            "He never said that in the quotation mark, quit lying. Or that's all you guys have left?\n",
            "\n",
            " said that in the quotation mark,. Or that's all you have left?\n",
            "\n",
            "You said that in the quotation mark, right. Or that's all you would have left?\n",
            "Batch_loss $0.7237:  48% 30999/64822 [2:39:47<3:05:21,  3.04it/s]30999\n",
            "Let's make it honest: Any number of witnesses, from across the political spectrum, have had memory lapses unexplainable by modern medicine when walking into House or Senate committee rooms to give testimony. Maybe all those brilliant legislative minds assembled in front of the witnesses make the witnesses stupefied.\n",
            "\n",
            "Let's make it honest: Any number of, from across the spectrum, have unexplainable by when walking into or Senate committee rooms to give testimony. all those legislative assembled in front of the witnesses make the witnesses stupefied.\n",
            "\n",
            "Let's make it honest: Any number of legislators, from across the political spectrum, have been completely unexplainable by themselves when walking into the House or Senate committee rooms to give testimony. And all those legislators and legislative staff assembled in front of the witnesses make the witnesses stupefied.\n",
            "Batch_loss $0.7212:  49% 31999/64822 [2:44:58<2:53:50,  3.15it/s]31999\n",
            "Diversity is our strength.\n",
            "\n",
            " is strength.\n",
            "\n",
            "This is their strength.\n",
            "Batch_loss $0.7193:  51% 32999/64822 [2:50:08<2:44:28,  3.22it/s]32999\n",
            "\"taste\" Democrats? We already have enough wingnut extremists in this state; let's not start encouraging cannibalism.\n",
            "\n",
            "taste\"? We already have enough wing extremists in this; let's not start encouraging cannibalism.\n",
            "\n",
            "\"taste\" people? We already have enough wingnut extremists in this country; let's not start encouraging cannibalism.\n",
            "Batch_loss $0.7175:  52% 33999/64822 [2:55:17<2:36:44,  3.28it/s]33999\n",
            "Sigh - another loss of pot tourist dollars for us, but another state closer to the repeal of the national prohibition, which will benefit more than just Colorado.\n",
            "\n",
            "S - another loss of dollars for, but another closer the repeal of the, which will benefit more than just.\n",
            "\n",
            "Soros - another loss of billions dollars for the US, but another step closer to the repeal of the ACA, which will benefit more than just us.\n",
            "Batch_loss $0.7155:  54% 34999/64822 [3:00:26<2:26:33,  3.39it/s]34999\n",
            "It's not you, it's her.  She has actually broadened her perspective.\n",
            "\n",
            "It's not it's. has broadened her perspective.\n",
            "\n",
            "It's not her opinion it's mine. She has clearly broadened her perspective.\n",
            "Batch_loss $0.7139:  56% 35999/64822 [3:05:35<2:36:55,  3.06it/s]35999\n",
            "Please don't conflate these issues.  There are many Christians who wholeheartedly support the science behind climate change.  Bringing faith into the conversation confuses issues and breaks down into personal attacks.\n",
            "\n",
            "Please don't conflate these issues.  There are who wholeheartedly support the behind. Bringing into the conversation confuses issues and breaks down into attacks.\n",
            "\n",
            "Please don't conflate these issues.  There are people who wholeheartedly support the religion behind this.  Bringing politics into the conversation confuses issues and breaks down into personal attacks.\n",
            "Batch_loss $0.7121:  57% 36999/64822 [3:10:44<2:17:41,  3.37it/s]36999\n",
            "get informed\n",
            "\n",
            "get\n",
            "\n",
            "get it\n",
            "Batch_loss $0.7107:  59% 37999/64822 [3:15:53<2:26:25,  3.05it/s]37999\n",
            "Just heard on the radio news that Texas estimates it will be short 120,000 DACA construction workers if this goes through and wondered who will rebuild Houston.\n",
            "\n",
            "Just heard on the radio news that estimates it will be 120,000 DACA if this goes through and wondered who will.\n",
            "\n",
            "Just heard on the radio news that Trump estimates it will be over 120,000 DACA people if this goes through and wondered who will vote.\n",
            "Batch_loss $0.7091:  60% 38999/64822 [3:21:03<2:05:00,  3.44it/s]38999\n",
            "Bummer for you.  My gray hairs were standing up all night. You don't sound like you have much of anything standing up all night anymore.\n",
            "\n",
            "B for you. up all night. You don't sound like you have much of up all night anymore.\n",
            "\n",
            "Bummer for you. You were up all night. You don't sound like you have much of a bed up late night anymore.\n",
            "Batch_loss $0.7075:  62% 39999/64822 [3:26:13<2:11:41,  3.14it/s]39999\n",
            "2 people with a severe'reality disconnect'.  Wonder which TV show, movie, or video game they had playing in their heads at the time?  For sure wasn't real life, unless they were both getting homesick for jail food.\n",
            "\n",
            " with a severe'.  Wonder which TV show, movie, or game had playing in at the time? For wasn't real life, unless they were getting for food.\n",
            "\n",
            "'People with a severe IQ disorder'.  Wonder which TV show, movie, or video game you had playing in your head at the time?  For me it wasn't real life, unless they were all getting paid for my food.\n",
            "Batch_loss $0.7060:  63% 40999/64822 [3:31:24<2:06:14,  3.15it/s]40999\n",
            "Ever wonder why girls were encouraged into nursing & boys to become doctors?\n",
            "\n",
            "Ever wonder why were encouraged into & to become?\n",
            "\n",
            "Ever wonder why boys were encouraged into sports & football to become football players?\n",
            "Batch_loss $0.7047:  65% 41999/64822 [3:36:34<1:56:35,  3.26it/s]41999\n",
            "Or somebody who rejected the teachings of the church.\n",
            "\n",
            "Or rejected the teachings of the.\n",
            "\n",
            "Orthodox Catholics rejected the teachings of the Church.\n",
            "Batch_loss $0.7035:  66% 42999/64822 [3:41:41<1:55:28,  3.15it/s]42999\n",
            "You have hope in connection with me, huh?   My goodness, that's just fascinating.\n",
            "\n",
            " have hope in with,?   My goodness, that's just.\n",
            "\n",
            "You have hope in Christ with him, right?   My goodness, that's just silly.\n",
            "Batch_loss $0.7022:  68% 43999/64822 [3:46:51<1:42:14,  3.39it/s]43999\n",
            "you think homophobia is normal? hahaha no wonder Notley is going to win.\n",
            "\n",
            "you think is? hahaha no wonder Notley is going to win.\n",
            "\n",
            "you think Alberta is homophobic? hahaha no wonder Notley is going to win.\n",
            "Batch_loss $0.7009:  69% 44999/64822 [3:52:00<1:38:13,  3.36it/s]44999\n",
            "I'm a middle aged white male, 4th generation, Canadian. Now my two sons who work their butts off and will soon be entering the work force have to also suffer for my so-called sins and privilege.   I feel used.\n",
            "\n",
            "I'm a, 4th,. Now my who their butts off and soon be entering the work force have to also suffer for my so-called sins and privilege.   I feel used.\n",
            "\n",
            "I'm a male, 4th generation, white. Now my daughters who worked their butts off and will soon be entering the work force have to also suffer for my so-called sins and privilege.   I feel used.\n",
            "Batch_loss $0.7001:  71% 45999/64822 [3:57:06<1:32:53,  3.38it/s]45999\n",
            "ie. the Help Me Save Our Jobs fund\n",
            "\n",
            "ie. the Help Save Our fund\n",
            "\n",
            "ie. the Help  Save Our State fund\n",
            "Batch_loss $0.6990:  73% 46999/64822 [4:02:12<1:28:06,  3.37it/s]46999\n",
            "Thanks for proving my point with the personal attacks.  Take an economics class or read a book. It'll make you a better Canadian.\n",
            "\n",
            "Thanks for proving point with the attacks.  Take an class or read a book. It'll make you a better.\n",
            "\n",
            "Thanks for proving your point with the personal attacks.  Take an English class or read a book. It'll make you a better writer.\n",
            "Batch_loss $0.6976:  74% 47999/64822 [4:07:20<1:28:11,  3.18it/s]47999\n",
            "Yeah, top honors from Wharton, Ivy-League educated business leader.....but I'm sure he's never heard of the term \"oligarchy.\". How does anyone permit your posts past Civil Comments- do you post everthing at 2 am when only you're awake?\n",
            "\n",
            "Yeah, top honors from Wh- leader.....but I'm sure's never heard of the term \".\". How does anyone permit your posts past Comments- do you post everthing at when only're?\n",
            "\n",
            "Yeah, top honors from Whiny old-guard leader.....but I'm sure he's never heard of the term \"journalist.\". How does anyone permit your posts past Civil Comments- do you post everthing at Civil Comments when only you're here?\n",
            "Batch_loss $0.6964:  76% 48999/64822 [4:12:30<1:21:41,  3.23it/s]48999\n",
            "Multiculturalism and diversity are code words for white genocide.\n",
            "\n",
            "iculturalism and diversity are code words for.\n",
            "\n",
            "Multiculturalism and diversity are code words for white genocide.\n",
            "Batch_loss $0.6953:  77% 49999/64822 [4:17:37<1:17:52,  3.17it/s]49999\n",
            "Now its up to the Governor and the Senate to be the adults. Obviously the House isn't capable of it.\n",
            "\n",
            "Now up to the the to be the. the isn't capable of it.\n",
            "\n",
            "Now its up to the rest of the country to be the judge. Maybe the state isn't capable of it.\n",
            "Batch_loss $0.6943:  79% 50999/64822 [4:22:44<1:05:44,  3.50it/s]50999\n",
            "\"Just shut up, tell your lame jokes, and collect your $10 mill a year- while you still can.\"  Hey, sourpuss, nobody forced you to comment on a subject you obviously don't care about.  Maybe it's time for your warm milk or a nap.\n",
            "\n",
            " up, tell, and collect $10 mill a year while still can.\"  Hey,p, forced you to on a subject don't care about.  Maybe it's time for warm milk or a nap.\n",
            "\n",
            "\"Lock her up, tell her to retire, and collect her $10 mill a year, while she still can.\"  Hey, \"p, she forced you to comment on a subject you don't care about.  Maybe it's time for a warm milk or a nap.\n",
            "Batch_loss $0.6934:  80% 51999/64822 [4:27:52<1:08:56,  3.10it/s]51999\n",
            "Your 7th repost because you don't want responses to your preachings?  Sad.\n",
            "\n",
            "Yourth repost because don want to?.\n",
            "\n",
            "Your 2th repost because you don't want to listen to me?  Sad.\n",
            "Batch_loss $0.6924:  82% 52999/64822 [4:33:00<1:00:25,  3.26it/s]52999\n",
            "It starts at the top. Trump is now the President and has done nothing to bring our country together.  He continues to degrade women at the highest level and has admitted to Sexual Assault.\n",
            "\n",
            "It starts at the top. Trump is now the President and has done nothing to bring our country together. He continues to degrade at the highest level and has admitted to.\n",
            "\n",
            "It starts at the top. Trump is now the President and has done nothing to bring our country together.  He continues to degrade women at the highest level and has admitted to sexually assaulting women.\n",
            "Batch_loss $0.6916:  83% 53999/64822 [4:38:10<53:46,  3.35it/s]53999\n",
            "Too bad, maybe your stomach can't handle rich food or just hard luck.  Never happened to me, lucky I guess.\n",
            "\n",
            "Too bad, maybe can handle or just hard luck. happened to, lucky I guess.\n",
            "\n",
            "Too bad, maybe he can't handle reality or just hard luck.  Never happened to me, lucky I guess.\n",
            "Batch_loss $0.6907:  85% 54999/64822 [4:43:20<54:36,  3.00it/s]54999\n",
            "Yup, they might have had Bushmasters, or Remingtons, or Colts, or (more likely in England) Brownings or Lee-Enfields. It's common to refer to firearms by the manufacturer's name.\n",
            "\n",
            "Yup, they have had Bushmasters, or Remingtons, or, or (more likely) or Lee-Enfields. It's common to refer to by the's name.\n",
            "\n",
            "Yup, they would have had Bushmasters, or Remingtons, or WWII, or (more likely) Korean War or Lee-Enfields. It's common to refer to people by the man's name.\n",
            "Batch_loss $0.6900:  86% 55999/64822 [4:48:28<43:40,  3.37it/s]55999\n",
            "An article in Business Day by Stuart Theobold suggest that the Guptas are running out of money in spte of the billions stolen. Perhaps that's why Molefe is in such a rush to get back into looting mode at Eskom?\n",
            "\n",
            "An article in by Stuart Theobold suggest that are running out of money inpte of the billions stolen. Perhaps that's why is in such a rush to get back into mode?\n",
            "\n",
            "An article in the G&M by Stuart Theobold suggest that we are running out of money in Trpte of the billions stolen. Perhaps that's why Trudeau is in such a rush to get back into business mode here?\n",
            "Batch_loss $0.6892:  88% 56999/64822 [4:53:36<35:55,  3.63it/s]56999\n",
            "Purgatory's a she?! 😮 I would never have guessed. Such hard-headed Catholicism. A spiritual tomboy, then.\n",
            "\n",
            "Purgatory's?! ðŁĺ® I would never have guessed. Such hard-headed. A, then.\n",
            "\n",
            "Purgatory's priest?! 😄 I would never have guessed. Such hard-headed people. A Catholic, then.\n",
            "Batch_loss $0.6884:  89% 57999/64822 [4:58:45<37:19,  3.05it/s]57999\n",
            "What other seminaries have benefited from this sad situation?\n",
            "\n",
            "What other have benefited from this situation?\n",
            "\n",
            "What other countries have benefited from this economic situation?\n",
            "Batch_loss $0.6877:  91% 58999/64822 [5:03:55<30:22,  3.19it/s]58999\n",
            "This is shocking to no one.  Anyone who wonders why the system never changes just needs to read this story.  Same thing every time.  This idiot Plotkin and his ilk are why this stuff keeps happening.\n",
            "\n",
            "This is shocking to no.  Anyone who wonders why the never changes just needs to read this story. thing every time. This Plotk why this stuff keeps happening.\n",
            "\n",
            "This is shocking to no one.  Anyone who wonders why the news media never changes just needs to read this story.  Same thing every time.  This Media Plot is the exact reason why this stuff keeps happening.\n",
            "Batch_loss $0.6868:  93% 59999/64822 [5:09:07<25:37,  3.14it/s]59999\n",
            "I think you'll find the church does accept them in fact contributes  in some instances.  Especially with clergy in relationships with women. Eureka St a Jesuit publication has an article by Stephen de Weger: Vatican 11 the sexual revolution and clergy sexual misconduct.\n",
            "\n",
            "I think you'll find the does accept them in fact contributes in some instances. Especially with in with. Eureka St a publication has an article by Stephen de Weger: 11 the revolution and misconduct.\n",
            "\n",
            "I think you'll find the Church does accept them in fact contributes them in some instances.  Especially with women in love with priests. Eureka St a Catholic publication has an article by Stephen de Weger:  11 the sexual revolution and sexual misconduct.\n",
            "Batch_loss $0.6860:  94% 60999/64822 [5:14:17<19:17,  3.30it/s]60999\n",
            "A bit racist there, Joe, don’t you think?    Replace a key descriptive adjective with the color brown or black in your statement “lazy, fat white man-boys” and see what happens.\n",
            "\n",
            "A bit there, Joe, donâĢt you think?    Replace a key descriptive adjective with the or in your statement âĢľlazy,âĢĿ and see what happens.\n",
            "\n",
            "A bit weak there, Joe, don’t you think?    Replace a key descriptive adjective with the white male or male in your statement “lazy, lazy” and see what happens.\n",
            "Batch_loss $0.6852:  96% 61999/64822 [5:19:27<15:37,  3.01it/s]61999\n",
            "Hmm.  Mindless and spontaneous boasting that endangers security if the US.  Yeah, hardly sounds like Trump at all.\n",
            "\n",
            "Hmm. and spontaneous boasting that endangers.  Yeah, hardly sounds like Trump at all.\n",
            "\n",
            "Hmm. Simple and spontaneous boasting that endangers our security.  Yeah, hardly sounds like Trump at all.\n",
            "Batch_loss $0.6844:  97% 62999/64822 [5:24:37<09:18,  3.27it/s]62999\n",
            "Well said, Paul.\n",
            "\n",
            "Well said,.\n",
            "\n",
            "Well said, John.\n",
            "Batch_loss $0.6836:  99% 63999/64822 [5:29:47<04:02,  3.40it/s]63999\n",
            "Why would the daughter of a draft dodger, who has just slapped the face of every serving American transgendered person be chosen for a ceremonial task of honour?  Time to for the government to remove her from the guest list.\n",
            "\n",
            "Why the of a draft dodger, who has just slapped the face of every serving be chosen for a ceremonial task of honour?  Time to for the government to remove from the guest list.\n",
            "\n",
            "Why would the wife of a draft dodger, who has just slapped the face of every serving military man be chosen for a ceremonial task of honour?  Time to for the government to remove trans people from the guest list.\n",
            "Batch_loss $0.6831: 100% 64822/64822 [5:34:03<00:00,  3.23it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"Bart_Label.py\", line 8, in <module>\n",
            "    train_generator(batch_size=3,max_length=64, lr=1e-5, epochs=3 ,mode=\"Bart\",attention_layer=10,\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Training/Training.py\", line 209, in train_generator\n",
            "    torch.save(model.state_dict(), save+str(epoch))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 377, in save\n",
            "    with _open_file_like(f, 'wb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 231, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 212, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'generations/Bart_test_label_attention_mean_640'\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "python3: can't open file 'Transfer.py': [Errno 107] Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "python3: can't open file 'Transfer_WR_Full.py': [Errno 107] Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "python3: can't open file 'Transfer_WR_50.py': [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PF_-Af-B4dN-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train the transfer pipeline and generate pairs using style transfer and word replacement.**\n",
        "###Results are found in folders Code/generations.\n",
        "######Note: Generating modified comments for all original comments in the dataset can take a long time.\n"
      ],
      "metadata": {
        "id": "rvcBw6OL0vWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!chmod +x Tables.sh"
      ],
      "metadata": {
        "id": "kFJYZkkr26EZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!./Tables.sh"
      ],
      "metadata": {
        "id": "6wmlzx4A7Y3T"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cLOLgQsZ4OkV"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}