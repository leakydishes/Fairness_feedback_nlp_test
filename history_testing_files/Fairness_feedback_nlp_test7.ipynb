{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "mount_file_id": "1jixwOITC2bjIzZRc388tdtr1wOYlxE2f",
      "authorship_tag": "ABX9TyOiCIlxK5KARAFm6wNg8r5X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leakydishes/Fairness_feedback_nlp_test/blob/main/Fairness_feedback_nlp_test7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Deakin University Internship 2023**\n",
        "##Human-Guided Fair Classification for NLP\n",
        "#####Te' Claire\n",
        "\n",
        "*@inproceedings{\n",
        "dorner2023humanguided,\n",
        "title={Human-Guided Fair Classification for Natural Language Processing},\n",
        "author={Florian E. Dorner and Momchil Peychev and Nikola Konstantinov and Naman Goel and Elliott Ash and Martin Vechev},\n",
        "booktitle={The Eleventh International Conference on Learning Representations },\n",
        "year={2023},\n",
        "url={https://openreview.net/forum?id=N_g8TT9Cy7f}\n",
        "}*"
      ],
      "metadata": {
        "id": "1krF2sLeA9Ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 1. Mount Google Drive**"
      ],
      "metadata": {
        "id": "rnMkrDpv5XY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuts1xQ2_yPd",
        "outputId": "34f85dc0-5c97-49ac-f5a6-8c7b783e38ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 2.Download the train.csv file from the Civil comments dataset to Code/Datasets/Kaggle_Toxicity**\n",
        "####Set up a virtual environment with the required packages"
      ],
      "metadata": {
        "id": "riJuKYPvAzPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Note: Google Colab already has Python pre-installed therefore you don't need to create a virtual environment. Instead install dependencies."
      ],
      "metadata": {
        "id": "gg9i_BeQoFoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/fairness-feedback-nlp-master/Code"
      ],
      "metadata": {
        "id": "2FKZmY_S5tzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4c08fa-0567-451b-80b0-5c09a75bd759"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/fairness-feedback-nlp-master/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install python3.8\n",
        "!python3.8 -m ensurepip --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n28vzRfUz52s",
        "outputId": "f0f35bd7-3f84-4c7c-abc8-9de835d23b06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [832 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,129 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [979 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,236 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 4,518 kB in 4s (1,221 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support python3.8\n",
            "  python3.8-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 5,099 kB of archives.\n",
            "After this operation, 18.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.17-1+jammy1 [793 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.17-1+jammy1 [2,023 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.17-1+jammy1 [1,817 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.17-1+jammy1 [438 kB]\n",
            "Fetched 5,099 kB in 8s (605 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 120831 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.8-minimal_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../1-python3.8-minimal_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.8-stdlib_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../5-python3.8_3.8.17-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.17-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-minimal (3.8.17-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.17-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "/usr/bin/python3.8: No module named ensurepip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list python versions\n",
        "!ls /usr/bin/python*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL268DydHzQk",
        "outputId": "c52a7621-d98e-44d7-bd20-5896be23868e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3     /usr/bin/python3.10-config  /usr/bin/python3-config\n",
            "/usr/bin/python3.10  /usr/bin/python3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#update python version\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY1Lq6kvCL4L",
        "outputId": "32d9a49f-65a6-476e-ab39-8e4be251580b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#permanently install the specific version to the google colab\n",
        "!sudo apt install python3-pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNdmmkSdF07T",
        "outputId": "8834452d-5eb8-464d-8376-ee1889b750f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,965 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.3 [1,305 kB]\n",
            "Fetched 1,677 kB in 2s (847 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 121482 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.3_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install correct packages\n",
        "!sudo apt-get install python3.8-distutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB9Yi1EY3wgN",
        "outputId": "f310bd1e-6dd6-4013-b517-04f0b2339fb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.8-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.8-distutils python3.8-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 319 kB of archives.\n",
            "After this operation, 1,237 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.17-1+jammy1 [126 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.17-1+jammy1 [193 kB]\n",
            "Fetched 319 kB in 3s (109 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "(Reading database ... 122344 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.8-lib2to3_3.8.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../python3.8-distutils_3.8.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.17-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.17-1+jammy1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Then, run"
      ],
      "metadata": {
        "id": "h2LyIOV-F9JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zAV5zxdl0d1N",
        "outputId": "157b00fa-307d-4aca-a1b4-d4d4318fbb7c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.22.3\n",
            "  Downloading numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.11.0\n",
            "  Downloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.0\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.18.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.4.2\n",
            "  Downloading pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.6.3\n",
            "  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 KB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m736.6/736.6 KB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2023.8.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.3/774.3 KB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 KB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 KB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec\n",
            "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas==1.4.2->-r requirements.txt (line 5)) (1.16.0)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 KB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 KB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click\n",
            "  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 KB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=7ca75a7710a6abefa77e33fd2366c8a665451c69b13b1c76d51f0f7398f180e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, pytz, urllib3, typing-extensions, tqdm, regex, pyyaml, python-dateutil, packaging, numpy, joblib, idna, fsspec, filelock, click, charset-normalizer, certifi, torch, scipy, sacremoses, requests, pandas, huggingface-hub, transformers\n",
            "Successfully installed certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.6 filelock-3.12.2 fsspec-2023.6.0 huggingface-hub-0.16.4 idna-3.4 joblib-1.3.2 numpy-1.22.3 packaging-23.1 pandas-1.4.2 python-dateutil-2.8.2 pytz-2023.3 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 sacremoses-0.0.53 scipy-1.6.3 tokenizers-0.12.1 torch-1.11.0 tqdm-4.64.0 transformers-4.18.0 typing-extensions-4.7.1 urllib3-2.0.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check file path and script is granted permission to be executed as a program"
      ],
      "metadata": {
        "id": "1qLnc0MiGGkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/fairness-feedback-nlp-master/Code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1ttbnMoGEMB",
        "outputId": "e1a91bd6-b4f8-4ed0-8bde-45caf078e7de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/fairness-feedback-nlp-master/Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!chmod +x Generation.sh\n",
        "!chmod +x Generation_Quick.sh"
      ],
      "metadata": {
        "id": "Pid4l5iuGMON"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Add transformers"
      ],
      "metadata": {
        "id": "vA6vY_zJGOeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlqlkPf8GN5T",
        "outputId": "040cba2d-4c66-4d77-fd91-2e7d71d30739"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.7.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.3.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source Fairness-Feedback-NLP/bin/activate"
      ],
      "metadata": {
        "id": "XVOCm-cjGCp-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Run code"
      ],
      "metadata": {
        "id": "Tu6ZHHic10Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./Generation_Quick.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9O0425u0lPL",
        "outputId": "070e83c8-dc73-45ac-f117-5d18255abfce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "216073\n",
            "21607\n",
            "epoch:  0\n",
            "Batch_loss $25.9289: 100% 12155/12155 [17:38<00:00, 11.48it/s]\n",
            "epoch:  1\n",
            "Batch_loss $27.1930: 100% 12155/12155 [17:22<00:00, 11.66it/s]\n",
            "epoch:  2\n",
            "Batch_loss $22.8955: 100% 12155/12155 [17:21<00:00, 11.67it/s]\n",
            "Testing on train\n",
            "100% 12155/12155 [04:46<00:00, 42.44it/s]\n",
            "train male\n",
            "tpr: tensor(0.9990, device='cuda:0')\n",
            "tnr: tensor(0.9416, device='cuda:0')\n",
            "loss: tensor(0.0130, device='cuda:0')\n",
            "train female\n",
            "tpr: tensor(0.9990, device='cuda:0')\n",
            "tnr: tensor(0.9508, device='cuda:0')\n",
            "loss: tensor(0.0082, device='cuda:0')\n",
            "train transgender\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9803, device='cuda:0')\n",
            "loss: tensor(0.0081, device='cuda:0')\n",
            "train other_gender\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2998, device='cuda:0')\n",
            "train heterosexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9422, device='cuda:0')\n",
            "loss: tensor(0.0134, device='cuda:0')\n",
            "train homosexual_gay_or_lesbian\n",
            "tpr: tensor(0.9997, device='cuda:0')\n",
            "tnr: tensor(0.9796, device='cuda:0')\n",
            "loss: tensor(0.0060, device='cuda:0')\n",
            "train bisexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.5042, device='cuda:0')\n",
            "loss: tensor(0.0557, device='cuda:0')\n",
            "train other_sexual_orientation\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2914, device='cuda:0')\n",
            "train christian\n",
            "tpr: tensor(0.9998, device='cuda:0')\n",
            "tnr: tensor(0.9326, device='cuda:0')\n",
            "loss: tensor(0.0122, device='cuda:0')\n",
            "train jewish\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9749, device='cuda:0')\n",
            "loss: tensor(0.0054, device='cuda:0')\n",
            "train muslim\n",
            "tpr: tensor(0.9998, device='cuda:0')\n",
            "tnr: tensor(0.9762, device='cuda:0')\n",
            "loss: tensor(0.0062, device='cuda:0')\n",
            "train hindu\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9530, device='cuda:0')\n",
            "loss: tensor(0.0146, device='cuda:0')\n",
            "train buddhist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9817, device='cuda:0')\n",
            "loss: tensor(0.0101, device='cuda:0')\n",
            "train atheist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9894, device='cuda:0')\n",
            "loss: tensor(0.0062, device='cuda:0')\n",
            "train other_religion\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.0001, device='cuda:0')\n",
            "loss: tensor(0.1495, device='cuda:0')\n",
            "train black\n",
            "tpr: tensor(0.9993, device='cuda:0')\n",
            "tnr: tensor(0.9865, device='cuda:0')\n",
            "loss: tensor(0.0042, device='cuda:0')\n",
            "train white\n",
            "tpr: tensor(0.9990, device='cuda:0')\n",
            "tnr: tensor(0.9925, device='cuda:0')\n",
            "loss: tensor(0.0034, device='cuda:0')\n",
            "train asian\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9543, device='cuda:0')\n",
            "loss: tensor(0.0119, device='cuda:0')\n",
            "train latino\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9563, device='cuda:0')\n",
            "loss: tensor(0.0190, device='cuda:0')\n",
            "train other_race_or_ethnicity\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.1443, device='cuda:0')\n",
            "loss: tensor(0.1172, device='cuda:0')\n",
            "train physical_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.0587, device='cuda:0')\n",
            "loss: tensor(0.1040, device='cuda:0')\n",
            "train intellectual_or_learning_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.6127, device='cuda:0')\n",
            "loss: tensor(0.0569, device='cuda:0')\n",
            "train psychiatric_or_mental_illness\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9703, device='cuda:0')\n",
            "loss: tensor(0.0077, device='cuda:0')\n",
            "train other_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2895, device='cuda:0')\n",
            "Testing on test\n",
            "100% 1351/1351 [00:31<00:00, 42.86it/s]\n",
            "test male\n",
            "tpr: tensor(0.9988, device='cuda:0')\n",
            "tnr: tensor(0.9381, device='cuda:0')\n",
            "loss: tensor(0.0133, device='cuda:0')\n",
            "test female\n",
            "tpr: tensor(0.9984, device='cuda:0')\n",
            "tnr: tensor(0.9520, device='cuda:0')\n",
            "loss: tensor(0.0082, device='cuda:0')\n",
            "test transgender\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9792, device='cuda:0')\n",
            "loss: tensor(0.0083, device='cuda:0')\n",
            "test other_gender\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.3005, device='cuda:0')\n",
            "test heterosexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9416, device='cuda:0')\n",
            "loss: tensor(0.0137, device='cuda:0')\n",
            "test homosexual_gay_or_lesbian\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9795, device='cuda:0')\n",
            "loss: tensor(0.0060, device='cuda:0')\n",
            "test bisexual\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.4922, device='cuda:0')\n",
            "loss: tensor(0.0563, device='cuda:0')\n",
            "test other_sexual_orientation\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2924, device='cuda:0')\n",
            "test christian\n",
            "tpr: tensor(0.9981, device='cuda:0')\n",
            "tnr: tensor(0.9315, device='cuda:0')\n",
            "loss: tensor(0.0125, device='cuda:0')\n",
            "test jewish\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9736, device='cuda:0')\n",
            "loss: tensor(0.0054, device='cuda:0')\n",
            "test muslim\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9761, device='cuda:0')\n",
            "loss: tensor(0.0061, device='cuda:0')\n",
            "test hindu\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9523, device='cuda:0')\n",
            "loss: tensor(0.0148, device='cuda:0')\n",
            "test buddhist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9803, device='cuda:0')\n",
            "loss: tensor(0.0102, device='cuda:0')\n",
            "test atheist\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9886, device='cuda:0')\n",
            "loss: tensor(0.0064, device='cuda:0')\n",
            "test other_religion\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(9.2571e-05, device='cuda:0')\n",
            "loss: tensor(0.1498, device='cuda:0')\n",
            "test black\n",
            "tpr: tensor(0.9957, device='cuda:0')\n",
            "tnr: tensor(0.9861, device='cuda:0')\n",
            "loss: tensor(0.0043, device='cuda:0')\n",
            "test white\n",
            "tpr: tensor(0.9989, device='cuda:0')\n",
            "tnr: tensor(0.9929, device='cuda:0')\n",
            "loss: tensor(0.0031, device='cuda:0')\n",
            "test asian\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9522, device='cuda:0')\n",
            "loss: tensor(0.0123, device='cuda:0')\n",
            "test latino\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9560, device='cuda:0')\n",
            "loss: tensor(0.0191, device='cuda:0')\n",
            "test other_race_or_ethnicity\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.1444, device='cuda:0')\n",
            "loss: tensor(0.1176, device='cuda:0')\n",
            "test physical_disability\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0.0544, device='cuda:0')\n",
            "loss: tensor(0.1050, device='cuda:0')\n",
            "test intellectual_or_learning_disability\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.6147, device='cuda:0')\n",
            "loss: tensor(0.0567, device='cuda:0')\n",
            "test psychiatric_or_mental_illness\n",
            "tpr: tensor(1., device='cuda:0')\n",
            "tnr: tensor(0.9709, device='cuda:0')\n",
            "loss: tensor(0.0078, device='cuda:0')\n",
            "test other_disability\n",
            "tpr: tensor(nan, device='cuda:0')\n",
            "tnr: tensor(0., device='cuda:0')\n",
            "loss: tensor(0.2899, device='cuda:0')\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "train epoch:  0\n",
            "Batch_loss $1.4030:   2% 999/64822 [02:12<2:25:06,  7.33it/s]999\n",
            "Don't forget to pay the ferryman or the tax man!\n",
            "\n",
            "Don't forget to pay the ferryman or the!\n",
            "\n",
            "Don't forget to pay the ferryman or the attendant!\n",
            "Batch_loss $0.9846:   3% 1999/64822 [04:21<2:14:07,  7.81it/s]1999\n",
            "You are absolutely right.  And this explains why women can never lead.  We just don't understand these principles, which are obviously too complicated for our simple intellects.\n",
            "\n",
            "You are absolutely right  And this explains why can never lead  We just don't understand these principles, which are obviously too complicated for simple\n",
            "\n",
            "You are absolutely right.  And this explains why women can never lead men.  We just don't understand these principles, which are obviously too complicated for men to be simple.\n",
            "Batch_loss $0.8314:   5% 2999/64822 [06:31<2:14:21,  7.67it/s]2999\n",
            "So why is he not charged for taking bribes? He's admitted to graft why aren't the conjobs going for this throat/  Oh wait they were in the next room with the NDP waiting for their turn at the one minute date.  And you wonder why Trump got in?  OMG\n",
            "\n",
            "So why is he not charged for taking bribes?'s admitted to why aren't the going for this throat/  Oh wait they were in the next with waiting for their turn at the minute date  And you wonder why Trump got in?  OMG\n",
            "\n",
            "So why is he not charged for taking bribes? He's admitted to taking bribes why aren't the women going for this throat/  Oh wait they were in the next room with him waiting for their turn at the 15 minute date.  And you wonder why Trump got in?  OMG\n",
            "Batch_loss $0.7547:   6% 3999/64822 [08:40<2:03:33,  8.20it/s]3999\n",
            "Conrad Black got started early on his life of crime, by stealing Upper Canada College exams and peddling illegal copies.  Ironic that a \"news\" publisher who depends on Copyright Protection for much of his income started out life as a scofflaw copyright criminal.\n",
            "\n",
            "Conrad got started early on life of crime, by stealing Upper and peddling illegal copies  Ironic that a \"news\" publisher who depends on Copyright Protection for much of income started out life as a scofflaw criminal\n",
            "\n",
            "Conrad Manning got started early on in life of crime, by stealing Upper House and peddling illegal copies.  Ironic that a \"news\" publisher who depends on Copyright Protection for much of his income started out life as a scofflaw criminal.\n",
            "Batch_loss $0.7046:   8% 4999/64822 [10:49<2:09:16,  7.71it/s]4999\n",
            "Where did you get the notion that God chose Israel because they were 'handy' in a theological sense?  Israel was God's chosen  people through Covenant. It was God that evolved their thinking towards monotheism.  Jesus was the fulfillment of the Covenant.\n",
            "\n",
            "Where did you get the notion that chose because they were 'handy' in a sense? was God's chosen  people through Covenant It was that evolved their thinking towards was the fulfillment of the Covenant\n",
            "\n",
            "Where did you get the notion that God chose Jews because they were 'handy' in a general sense? God was God's chosen  people through Covenant Covenant. It was God that evolved their thinking towards. God was the fulfillment of the Covenant.\n",
            "Batch_loss $0.6713:   9% 5999/64822 [13:00<2:10:24,  7.52it/s]5999\n",
            "White-hating, racist shitbag you are wyatt dick.\n",
            "\n",
            "-hating, shitbag you are wyatt dick\n",
            "\n",
            "White-hating, white supremacist shitbag you are wyatt dick\n",
            "Batch_loss $0.6453:  11% 6999/64822 [15:08<1:58:20,  8.14it/s]6999\n",
            "\"Some states have declared a public health emergency because newly married men cannot get \"excited\" by anything other than \"deviant\" sex.\"  Really?  Post a link to prove it.\n",
            "\n",
            "\"Some states have declared a public health emergency because cannot get \"excited\" by anything other than \"\".\"  Really?  Post a link to prove it\n",
            "\n",
            "\"Some states have declared a public health emergency because men cannot get \"excited\" by anything other than \"male\" health issues.\"  Really?  Post a link to prove it.\n",
            "Batch_loss $0.6263:  12% 7999/64822 [17:18<2:00:41,  7.85it/s]7999\n",
            "I doubt there’s a non-sexist way to explain why it’s only women who hide their faces.\n",
            "\n",
            "I doubt thereâĢĻs a-ist way to explain why itâĢĻs only who hide their faces\n",
            "\n",
            "I doubt there’s a gender-neutralist way to explain why it”s only women who hide their faces.\n",
            "Batch_loss $0.6110:  14% 8999/64822 [19:27<1:57:03,  7.95it/s]8999\n",
            "Yes. But many of those voters are deserting him at this very moment. Thousands every day. They thought they'd try voting Republican for the first time - and Trump's performance has already ruined the party's near future. The sooner they get rid of him, the better the party's future.\n",
            "\n",
            "Yes But many of those voters are deserting at this very moment. Thousands every They thought they'd try for the first time - and's performance has already ruined the's near future The sooner they get rid of him, the better the's future\n",
            "\n",
            "Yes. But many of those voters are deserting Trump at this very moment. Thousands every year. They thought they'd try him for the first time - and he's performance has already ruined the country's near future. The sooner they get rid of him, the better the nation's future.\n",
            "Batch_loss $0.5984:  15% 9999/64822 [21:38<1:51:09,  8.22it/s]9999\n",
            "Casting a vote for Trump because Hillary was a woman and then being fearful of Trumps new executive orders all say you are not thinking thing through well.\n",
            "\n",
            "Casting a vote for Trump because Hillary and then being fearful of new orders all say you are not thing through well\n",
            "\n",
            "Casting a vote for Trump because Hillary and then being fearful of his new executive orders all say you are not thinking this thing through well.\n",
            "Batch_loss $0.5872:  17% 10999/64822 [23:46<1:58:01,  7.60it/s]10999\n",
            "Got. Proof? Didnt think so!!\n",
            "\n",
            "Got.? Didnt think so!!\n",
            "\n",
            "Got. Did? Didnt think so!!\n",
            "Batch_loss $0.5773:  19% 11999/64822 [25:56<1:48:04,  8.15it/s]11999\n",
            "Harpy, actually it speaks volumes about their journalism skills. Up there with National Enquirer!\n",
            "\n",
            "Harpy, actually it speaks volumes about their skills Up there with En!\n",
            "\n",
            "Harpy, actually it speaks volumes about their skill skills. Up there with the Enquirer!\n",
            "Batch_loss $0.5697:  20% 12999/64822 [28:05<1:53:52,  7.59it/s]12999\n",
            "Seriously, Wente? Girl, you sound so old and crotchety...laughable analysis here.\n",
            "\n",
            "Seriously, Wente?, you sound so and crotchety...laughable analysis here\n",
            "\n",
            "Seriously, Wente?  Man, you sound so sexist and crotchety...laughable analysis here.\n",
            "Batch_loss $0.5617:  22% 13999/64822 [30:15<1:47:04,  7.91it/s]13999\n",
            "The author of a book on Trump descriibed him as a 70 year old man with the mentality of a 13 year old, on that basis we have a 40 something year old with the mentatal ability of a 9 ear old. The 13 year old will win hands down.\n",
            "\n",
            "The author of a book on Trump descriibed him as a 70 year old with the of 13 year old, on that basis we have a 40 something year old with of old The 13 year old will win hands down\n",
            "\n",
            "The author of a book on Trump descriibed him as a 70 year old man with the age of a 13 year old, on that basis we have a 40 something year old with the maturity of a 12 year old. The 13 year older will win hands down.\n",
            "Batch_loss $0.5559:  23% 14999/64822 [32:24<1:47:12,  7.75it/s]14999\n",
            "What an ignorant comment.  You need to get out of your trailer park more and learn a bit about different people.  One Muslim nutjob said something to you and you are now trying to apply that to 1.3 billion others?\n",
            "\n",
            "What an comment  You need to get out of your trailer park more and learn a bit about different said something to you and you are now trying to apply that to 1.3 others?\n",
            "\n",
            "What an ignorant comment.  You need to get out of your trailer park more and learn a bit about different religions.  Islam said something to you and you are now trying to apply that to 1.3 billion others?\n",
            "Batch_loss $0.5507:  25% 15999/64822 [34:34<1:47:07,  7.60it/s]15999\n",
            "\"We can end homelessness in Canada\"  No we can't.\n",
            "\n",
            "\"We can end in\"  No we can't\n",
            "\n",
            "\"We can end slavery in Canada\"  No we can't.\n",
            "Batch_loss $0.5459:  26% 16999/64822 [36:44<1:38:03,  8.13it/s]16999\n",
            "the was the liberal left went nuts over George  Bush  you would think  \"that would cure America of conservatism for good.\"'but it did not even after tasting George Bush  American wanted more of that taste and in came Trump ------- so much for Ambrose99 wish\n",
            "\n",
            "the was the went over  Bush  you would think  \"that would cure of for good.\"'but it did not even after tasting George Bush wanted more of that taste and in came Trump ------- so much for Ambrose99 wish\n",
            "\n",
            "the was the one who went bankrupt over his  Bush  you would think  \"that would cure us of him for good.\"'but it did not even after tasting George Bush. we wanted more of that taste and in came Trump ------- so much for Ambrose99 wish.\n",
            "Batch_loss $0.5412:  28% 17999/64822 [38:57<1:44:21,  7.48it/s]17999\n",
            "Brock Turner. Owen Labrie. Austin James Wilkerson Steubenville  It's okay. It's just safer to assume all men are rapists. We cool, bro?\n",
            "\n",
            "Brock Turner. Owen Labrie. James Wilkerson Steville  It's okay It's just safer to assume all are We, bro?\n",
            "\n",
            "Brock Turner. Mr. Owen Labrie. Mr James Wilkerson Steubenville  It's okay. It's just safer to assume all men are rapists. Weasel, bro?\n",
            "Batch_loss $0.5372:  29% 18999/64822 [41:06<1:39:00,  7.71it/s]18999\n",
            "Over 500 companies and 4 failed? Wow he is greater at business than I thought. Great comment to show how smart Trump has been.\n",
            "\n",
            "Over and 4 failed? Wow is greater at than I thought Great comment to show how Trump has been\n",
            "\n",
            "Over 3 years and 4 failed? Wow Trump is greater at lying than I thought. Great comment to show how incompetent Trump has been.\n",
            "Batch_loss $0.5333:  31% 19999/64822 [43:19<1:37:08,  7.69it/s]19999\n",
            "This could sink the Liberal government.  One can hope.  But what a gift as an election issue.  Outrageous.\n",
            "\n",
            "This could sink the government  One can hope  But what a gift as an.  Outrageous\n",
            "\n",
            "This could sink the Liberal government.  One can hope.  But what a gift as an MP.  Outrageous.\n",
            "Batch_loss $0.5298:  32% 20999/64822 [45:28<1:32:06,  7.93it/s]20999\n",
            "\"... deplored by and vanquishing any and all establishment factions.\"  Actually he's stuck up to his neck in these \"establishment factions\" that you speak of.    He wanted to drain the swamp and now he's bogged down in it.\n",
            "\n",
            "\"... deplored by and vanquishing any and all factions.\"  Actually's stuck up to neck in these \" factions\" that you speak of wanted to drain the and now's bogged down in it\n",
            "\n",
            "\"... deplored by and vanquishing any and all two factions.\"  Actually he's stuck up to his neck in these \"two factions\" that you speak of.  He wanted to drain the swamp and now he's bogged down in it.\n",
            "Batch_loss $0.5261:  34% 21999/64822 [47:41<1:34:12,  7.58it/s]21999\n",
            "To clarify, Obama traded 5 terrorists for and praised a man who caused the crippling of two of his fellow soldiers.  Trump has not released his tax returns.  Which is worse.\n",
            "\n",
            "To clarify, Obama traded 5 for and praised a who caused of his fellow soldiers  Trump has not released his tax returns  Which is worse\n",
            "\n",
            "To clarify, Obama traded 5 years for and praised a man who caused the deaths of his fellow soldiers.  Trump has not released his tax returns.  Which is worse.\n",
            "Batch_loss $0.5232:  35% 22999/64822 [49:52<1:35:46,  7.28it/s]22999\n",
            "Women's breasts are every bit as uniquely identifiable as faces; men's, not quite so much.\n",
            "\n",
            "'s are every bit as uniquely identifiable as faces;'s, not quite so much\n",
            "\n",
            "Women's bodies are every bit as uniquely identifiable as faces; men's, not quite so much.\n",
            "Batch_loss $0.5204:  37% 23999/64822 [52:05<1:31:12,  7.46it/s]23999\n",
            "Interesting choice of emphasis by Ibby and the Globe.  No mention of the Gulf states?  It's all fine for LGBTTQQ2S people in Africa?\n",
            "\n",
            "Interesting choice of emphasis by Ibby and the Globe  No mention of the states?  It's all fine forT2S in?\n",
            "\n",
            "Interesting choice of emphasis by Ibby and the Globe.  No mention of the US states?  It's all fine for the TFW2S in Canada?\n",
            "Batch_loss $0.5182:  39% 24999/64822 [54:15<1:32:35,  7.17it/s]24999\n",
            "Lost to automation for the most part.  Some were moved to Mexico, but not to the extent people think.  They weren't'sold' in any case.  I'm not even sure how you would sell a job.\n",
            "\n",
            "Lost for the most part  Some were moved, but not to the extent think  They weren't'sold' in any case  I'm not even sure how you would sell a job\n",
            "\n",
            "Lost him for the most part.  Some were moved here, but not to the extent I think.  They weren't'sold' in any case.  I'm not even sure how you would sell a job.\n",
            "Batch_loss $0.5155:  40% 25999/64822 [56:28<1:20:54,  8.00it/s]25999\n",
            "Dissociative Identity Disorder?\n",
            "\n",
            "Dative Disorder?\n",
            "\n",
            "Diseasedative Psychosis Disorder?\n",
            "Batch_loss $0.5133:  42% 26999/64822 [58:38<1:23:46,  7.52it/s]26999\n",
            "Sorry, Rik. I'm not prepared to \"jump the shark\" and conflate a county mental health/criminal justice challenge with more international concerns.\n",
            "\n",
            "Sorry, Rik I'm not prepared to \"jump the shark\" and conflate a/criminal justice challenge with more concerns\n",
            "\n",
            "Sorry, Rik. I'm not prepared to \"jump the shark\" and conflate a political/criminal justice challenge with more ethical concerns.\n",
            "Batch_loss $0.5110:  43% 27999/64822 [1:00:47<1:18:46,  7.79it/s]27999\n",
            "This perv is incorrigible.  For the good of our meiji and society, this POS needs to be put down like a rabid dog.  He has already destroyed too many lives.\n",
            "\n",
            "This is incorrigible  For the good of and society, this POS needs to be put down like a rabid dog  He has already destroyed too many lives\n",
            "\n",
            "This man is incorrigible.  For the good of humanity and society, this POS needs to be put down like a rabid dog.  He has already destroyed too many lives.\n",
            "Batch_loss $0.5090:  45% 28999/64822 [1:02:57<1:20:00,  7.46it/s]28999\n",
            "PSU needs these funds so they can continue to have such programs as the recent white race bashing program.\n",
            "\n",
            "PSU needs these funds so they can continue to have such programs as the recent bashing program\n",
            "\n",
            "PSU needs these funds so they can continue to have such programs as the recent white man bashing program.\n",
            "Batch_loss $0.5066:  46% 29999/64822 [1:05:07<1:13:53,  7.85it/s]29999\n",
            "love you man.  and I enjoy your posting.  I love your sense of humor\n",
            "\n",
            " you  and I enjoy your posting  I love your sense of\n",
            "\n",
            "Man you are funny  and I enjoy your posting.  I love your sense of humor.\n",
            "Batch_loss $0.5047:  48% 30999/64822 [1:07:17<1:09:58,  8.06it/s]30999\n",
            "If they keep the operations here in Eugene going, there is no good reason at all for anyone to boycott Hop Valley beers.\n",
            "\n",
            "If they keep the operations in going, there is no good reason at all for anyone to boycott\n",
            "\n",
            "If they keep the operations in Canada going, there is no good reason at all for anyone to boycott.\n",
            "Batch_loss $0.5030:  49% 31999/64822 [1:09:27<1:13:14,  7.47it/s]31999\n",
            "We can only hope they are kicked out after implementation of tolls. The new regime can get rid of them or kick them out as well. Just another tax.\n",
            "\n",
            " can only hope they are kicked out after implementation ofs The new regime can get rid of them or kick them out as well. Just another\n",
            "\n",
            "They can only hope they are kicked out after implementation of Trumpcares. The new regime can get rid of them or kick them out as well. Just another socialist.\n",
            "Batch_loss $0.5012:  51% 32999/64822 [1:11:36<1:07:46,  7.83it/s]32999\n",
            "See a lawyer BEFORE there is trouble... to look over a contract, do a will and ensure your business is legally compliant... that is a good investment and relatively inexpensive... wait until AFTER there is trouble, you are in the hands of litigation lawyers and there will be no end to your expense.\n",
            "\n",
            "See a BEFORE there is trouble... to look over a contract, do a and ensure your is... that is a good and relatively inexpensive... wait until AFTER there is trouble, you are in the hands of and there will be no end to expense\n",
            "\n",
            "See a lawyer BEFORE there is trouble... to look over a contract, do a budget and ensure your income tax is affordable... that is a good business and relatively inexpensive... wait until AFTER there is distress, you are in the hands of politicians and there will be no end to your expense.\n",
            "Batch_loss $0.4997:  52% 33999/64822 [1:13:47<1:09:55,  7.35it/s]33999\n",
            "Partially true. But having more people take public transit puts off expensive infrastructure projects like new bridges and highways. Not to mention less pollution in our crowded cities. Valid arguments on both sides.\n",
            "\n",
            "Partially true But having more take public puts off expensive infrastructure projects like new bridges and Not to mention less in. Valid arguments on sides\n",
            "\n",
            "Partially true. But having more people take public transit puts off expensive infrastructure projects like new bridges and rail. Not to mention less people in transit. Valid arguments on both sides.\n",
            "Batch_loss $0.4979:  54% 34999/64822 [1:15:56<1:04:46,  7.67it/s]34999\n",
            "You may wish to address your question to Jesus Christ Himself. I did not make this divine command, nor did the Church.\n",
            "\n",
            "You may wish to address your question to I did not make this command, nor did the\n",
            "\n",
            "You may wish to address your question to God. I did not make this command, nor did the pope.\n",
            "Batch_loss $0.4965:  56% 35999/64822 [1:18:06<1:05:48,  7.30it/s]35999\n",
            "They weren't being serious that it's neato to pepper-spray people, they were poking fun at Neil Black and his endless banter and use of the phrase \"Another neato gun owner\".\n",
            "\n",
            "They weren't being that it's neato to pepper-spray, they were poking fun at Neil and his endless banter and use of the phrase \"Another neato owner\".\n",
            "\n",
            "They weren't being racist that it's neato to pepper-spray black people, they were poking fun at Neil Black and his endless banter and use of the phrase \"Another neato gun owner\".\n",
            "Batch_loss $0.4954:  57% 36999/64822 [1:20:17<57:12,  8.10it/s]36999\n",
            "Women should not be playing basketball, they should be having NCAA baking contests.\n",
            "\n",
            " should not be playing basketball, they should be having baking contests\n",
            "\n",
            "Women should not be playing basketball, they should be having female baking contests.\n",
            "Batch_loss $0.4945:  59% 37999/64822 [1:22:27<55:10,  8.10it/s]37999\n",
            "Why is the below \"history\"?  Other than the fact that is was accomplished in the past.  \"U.S. fencer Ibti Muhammad, a Muslim, made history by being the first woman to compete in the Olympics wearing a hijab, taking a bronze medal in fencing.\"\n",
            "\n",
            "Why is the below \"history\"?  Other than the fact that is was accomplished in the past  \".. f Ii, a, made history by being the first to compete in the wearing a, taking a bronze medal in fencing.\"\n",
            "\n",
            "Why is the below \"history\"?  Other than the fact that is was accomplished in the past.  \"U.S. fencer.    Iqiqi, a woman, made history by being the first woman to compete in the Olympics wearing a hijab, taking a bronze medal\n",
            "Batch_loss $0.4931:  60% 38999/64822 [1:24:39<57:38,  7.47it/s]38999\n",
            "You obviously have no idea what an 'newly discovered exploit\" is and that without upgrades/updates its just a matter of time before your systems go down. It is the lack of value placed on professional IT labour at the root of the majority of the problems we are seeing these days.\n",
            "\n",
            "You obviously have no idea what annewly discovered\" is and that without upgrades/updates its just a matter of time before your systems go down It is the lack of value placed on at the root of the majority of the problems are seeing these days\n",
            "\n",
            "You obviously have no idea what an \"newly discovered technology\" is and that without upgrades/updates its just a matter of time before your systems go down. It is the lack of value placed on technology at the root of the majority of the problems we are seeing these days.\n",
            "Batch_loss $0.4915:  62% 39999/64822 [1:26:48<53:10,  7.78it/s]39999\n",
            "Call me sir,as in Yes sir and No sir, and e will get along fine.\n",
            "\n",
            "Call me,as in sir and, and e will get along fine\n",
            "\n",
            "Call me sir,as in sir and sir, and e will get along fine.\n",
            "Batch_loss $0.4902:  63% 40999/64822 [1:28:57<52:59,  7.49it/s]40999\n",
            "He took the easy way! What if we did not have the PFD, what would he have done? Maybe cut Bonuses to all state legislators!  That would be a start!\n",
            "\n",
            " took the way! What if did not have the P, what would have done? Maybe cut Bonuses to all!  That would be a start!\n",
            "\n",
            "She took the easy way! What if she did not have the PFD, what would she have done? Maybe cut Bonuses to all employees!  That would be a start!\n",
            "Batch_loss $0.4890:  65% 41999/64822 [1:31:08<47:55,  7.94it/s]41999\n",
            "We do not know much about the dairy industry, but we are surprised this industry still cannot stand on its own legs and still is in need for the government's money teat.\n",
            "\n",
            " do not know much about the, but we are surprised this still on its own legs and still is in need for the government's money teat\n",
            "\n",
            "We do not know much about the economy, but we are surprised this country still stands on its own legs and still is in need for the government's money teat.\n",
            "Batch_loss $0.4876:  66% 42999/64822 [1:33:19<49:12,  7.39it/s]42999\n",
            "I mean, they didn't enforce the laws for the last 8 years, why start now?\n",
            "\n",
            "I mean, didn't for the last 8 why start now?\n",
            "\n",
            "I mean, he didn't vote for the last 8 years why start now?\n",
            "Batch_loss $0.4865:  68% 43999/64822 [1:35:29<43:44,  7.93it/s]43999\n",
            "Well, IF they make it into the playoffs, then they are playoff worthy.\n",
            "\n",
            "Well, IF they make it into, then they are playoff worthy\n",
            "\n",
            "Well, IF they make it into the playoffs, then they are playoff worthy.\n",
            "Batch_loss $0.4856:  69% 44999/64822 [1:37:38<41:26,  7.97it/s]44999\n",
            "In similar fashion, skyofblue blamed the Quebec City mosque killings on Justin Trudeau.\n",
            "\n",
            "In similar fashion, skyofblue blamed the City killings on Justin Trudeau\n",
            "\n",
            "In similar fashion, skyofblue blamed the Quebec City mosque killings on Justin Trudeau.\n",
            "Batch_loss $0.4846:  71% 45999/64822 [1:39:47<42:57,  7.30it/s]45999\n",
            "Europe white population is 15% of the world and falling fast reason mentioned above. In another 50 years it will be less then 10%. Extinct ethnic group,\n",
            "\n",
            " population is 15% of the world and falling fast reason mentioned above In another 50 years it will be less then 10%. Extinct group,\n",
            "\n",
            "White population is 15% of the world and falling fast reason mentioned above. In another 50 years it will be less then 10%. Extinct race group,\n",
            "Batch_loss $0.4835:  73% 46999/64822 [1:41:56<37:39,  7.89it/s]46999\n",
            "I've yet to read that NYT article, but now that you've provided a few lines of it I will be sure to get to it soon.  Hope you are well, Sarasi1 - and I continue to enjoy and value your comments.  Many blessings to you.\n",
            "\n",
            "I've yet to that, but now that you've provided a few of it I will be sure to get to it soon  Hope you are, Sar - and continue to enjoy and value your comments  Many to\n",
            "\n",
            "I've yet to read that article, but now that you've provided a few examples of it I will be sure to get to it soon.  Hope you are reading, Sarada - and I continue to enjoy and value your comments.  Many thanks to you.\n",
            "Batch_loss $0.4826:  74% 47999/64822 [1:44:07<38:26,  7.29it/s]47999\n",
            "The state and the city of Anchorage are different. This article is talking about Anchorage. This is pretty basic stuff.\n",
            "\n",
            "The and the of are different This article is talking about This is pretty basic stuff\n",
            "\n",
            "The sexes and the sexes of men are different. This article is talking about sex. This is pretty basic stuff.\n",
            "Batch_loss $0.4815:  76% 48999/64822 [1:46:17<33:09,  7.95it/s]48999\n",
            "Good- I know this won't be popular with those still looking for a free ride but it was the right decision.\n",
            "\n",
            "- know this won't be popular with still looking for a but it was the right\n",
            "\n",
            "I-I know this won't be popular with people still looking for a comment but it was the right decision.\n",
            "Batch_loss $0.4805:  77% 49999/64822 [1:48:28<32:24,  7.62it/s]49999\n",
            "Hmm, such vigor from the Liberal Globe to go after Rona, Did you ever wonder why the Globe does not go after the Liberals on the billions they give to their media competitor the CBC?  The Globe get millions in advertising  dollars from the CBC to advertise their programming.\n",
            "\n",
            "Hmm, such vigor from the Globe to go after Rona, Did you ever wonder why the does not go after the on the they give to their?  The Globe get in  dollars from the to advertise programming.\n",
            "\n",
            "Hmm, such vigor from the Globe to go after Rona, Did you ever wonder why the Globe does not go after the people on the news they give to their readers?  The Globe get millions in tax  dollars from the CBC to advertise their programming.\n",
            "Batch_loss $0.4796:  79% 50999/64822 [1:50:39<29:00,  7.94it/s]50999\n",
            "Islam frightens me when I think of my daughters in an Islamized Canada, when I think of what happened anywhere else in the world that Islam has gone.  I think this fear is legitimate, not a \"phobia\".\n",
            "\n",
            " frightens me when I think of my in anized, when I think of what happened anywhere else in the world that has gone  I think this fear is legitimate, not a \"phobia\".\n",
            "\n",
            "Islam frightens me when I think of my son in an Islamicized world, when I look of what happened anywhere else in the world that he has gone.  I think this fear is legitimate, not a \"phobia\".\n",
            "Batch_loss $0.4788:  80% 51999/64822 [1:52:50<26:48,  7.97it/s]51999\n",
            "Redi: Shaun Abrahams disappears like the Cheshire Cat, except it is not the grin, but the eyebrows that remain. And that is all he actually consists of.\n",
            "\n",
            "Redi: Shaun Abrahams disappears like thehire, except it is not the, but that remain And that is all actually consists of\n",
            "\n",
            "Redi: Shaun Abrahams disappears like the haolehire cat, except it is not the cats, but dogs that remain. And that is all he actually consists of.\n",
            "Batch_loss $0.4779:  82% 52999/64822 [1:55:01<25:35,  7.70it/s]52999\n",
            "How cool would it be if tRump brought down both the GOP and Faux \"News\"?\n",
            "\n",
            "How cool would it be if tRump brought down both the and \"\"?\n",
            "\n",
            "How cool would it be if tRump brought down both the FBI and the \"FBI\"?\n",
            "Batch_loss $0.4770:  83% 53999/64822 [1:57:11<23:02,  7.83it/s]53999\n",
            "Jesus already told us what He thinks on the subject of remarriage after divorce. I've had innocent victims of divorce in my family (not abuse) and encouraging them to commit mortal sins is not something that remotely has crossed my mind.\n",
            "\n",
            " already told what thinks on the subject of remar after I've had innocent victims of divorce in my (not abuse) and encouraging them to commit sins is not something that remotely has crossed my mind\n",
            "\n",
            "Jesus already told us what he thinks on the subject of remarriage after adultery. I've had innocent victims of divorce in my family (not abuse) and encouraging them to commit sexual sins is not something that remotely has crossed my mind.\n",
            "Batch_loss $0.4762:  85% 54999/64822 [1:59:22<21:23,  7.65it/s]54999\n",
            "When the storm surge is predicted to be 6,000 feet, warn me.\n",
            "\n",
            "When the is predicted to be,000 feet, warn\n",
            "\n",
            "When the sun is predicted to be 2,000 feet, warn.\n",
            "Batch_loss $0.4755:  86% 55999/64822 [2:01:34<18:54,  7.78it/s]55999\n",
            "\"So if alcohol is such a major factor, why don’t we warn young women about the risks of heavy drinking?\"  Nothing kicks off a Wente column like a straw man argument.\n",
            "\n",
            "\"So if is such a major factor, why donâĢĻt we warn about the risks of drinking?\"  Nothing kicks off a Wente column like a straw argument\n",
            "\n",
            "\"So if alcohol is such a major factor, why don’t we warn women about the risks of alcohol drinking?\"  Nothing kicks off a Wente column like a straw man argument.\n",
            "Batch_loss $0.4747:  88% 56999/64822 [2:03:43<17:15,  7.56it/s]56999\n",
            "High five Dana!!! You got this lady.. This program is worth donations as she has proved her passion. Great job!\n",
            "\n",
            "High Dana!!! You got this.. This is worth donations as she has proved her passion Great job!\n",
            "\n",
            "High five Dana!!! You got this girl.. This woman is worth donations as she has proved her passion. Great job!\n",
            "Batch_loss $0.4741:  89% 57999/64822 [2:05:53<14:19,  7.94it/s]57999\n",
            "WHERE is that \"fading into the background\"? More news on this front broke in the past week.   The investigation is still ongoing.\n",
            "\n",
            "WHERE is that \"f into the background\"? More news on this front broke in the past   The investigation is still ongoing\n",
            "\n",
            "WHERE is that \"fumbling into the background\"? More news on this front broke in the past.   The investigation is still ongoing.\n",
            "Batch_loss $0.4734:  91% 58999/64822 [2:08:04<12:23,  7.84it/s]58999\n",
            "Thanks, graybeard.  You learn something new every day!!!!  :)\n",
            "\n",
            "Thanks,  You learn something new every!!!!  :)\n",
            "\n",
            "Thanks, John.  You learn something new every day!!!!  :)\n",
            "Batch_loss $0.4728:  93% 59999/64822 [2:10:13<10:55,  7.36it/s]59999\n",
            "just as Alexander replied I am in shock that anybody able to get paid $8538 in 4 weeks on the  computer. read review............. http://www.jobpro22.com\n",
            "\n",
            "just as Alexander replied I am in shock that able to get $38 in 4 on the. read review............. http://www.procom\n",
            "\n",
            "just as Alexander replied I am in shock that he able to get me $138 in 4 hours on the internet. read review............. http://www.marketpro.com\n",
            "Batch_loss $0.4720:  94% 60999/64822 [2:12:21<07:46,  8.20it/s]60999\n",
            "What an absolute pile of rubbish. We are all much better off now that the Obushtons (to paraphrase Lord Black of Crossharbour) has been sent packing. Good riddance, let's get on with it.\n",
            "\n",
            "What an absolute pile of rubbish We are all much better off now that the Ob (to paraphrase of Crossharbour) has been sent packing. Good riddance, let's get on with it\n",
            "\n",
            "What an absolute pile of rubbish. We are all much better off now that the Obummer (to paraphrase the Lord of Crossharbour) has been sent packing. Good riddance, let's get on with it.\n",
            "Batch_loss $0.4714:  96% 61999/64822 [2:14:31<06:03,  7.76it/s]61999\n",
            "You mean the big nothing burger about the Mueller indictments with no mention of Trump that you guys got served on Monday?\n",
            "\n",
            "You mean the big nothing burger about the indictments with no mention of that you got served on?\n",
            "\n",
            "You mean the big nothing burger about the two indictments with no mention of the one that you both got served on Friday?\n",
            "Batch_loss $0.4708:  97% 62999/64822 [2:16:41<03:55,  7.75it/s]62999\n",
            "Are there going to be new housing on the mainland,or are the houses going to be moved? How did the Chinese make islands?\n",
            "\n",
            "Are there going to be new housing on the mainland,or are the going to be moved? How did make islands?\n",
            "\n",
            "Are there going to be new housing on the mainland,or are the residents going to being moved? How did the Chinese make islands?\n",
            "Batch_loss $0.4700:  99% 63999/64822 [2:18:50<01:40,  8.23it/s]63999\n",
            "IRT Melody Heidel &  Michel Grotstein - Correct! How-a-bout it SA?  Better Coverage! Women work just as hard as the males do. Better Coverage NOW!\n",
            "\n",
            "IRT Melody Heidel &  Michel Grotstein - Correct! How-a-bout it SA?  Better Coverage! work just as hard as do Better Coverage NOW!\n",
            "\n",
            "IRT Melody Heidel &  Michel Grotstein - Correct! How-a-bout it SA?  Better Coverage!  Women work just as hard as men do. Better Coverage NOW!\n",
            "Batch_loss $0.4695: 100% 64822/64822 [2:20:38<00:00,  7.68it/s]\n",
            "train_total_loss: 0.46949945902105616\n",
            "test epoch:  0\n",
            "  0% 0/7203 [00:00<?, ?it/s]Edward: I never heard  bad word spoken about Len Tose. If anything, he gave away too much of himself. I don't think the Archbishop or the Archdiocese of Philadelphia would ever hire a strong Jewish woman to represent them. They never had a kind word for Lynn Abraham.\n",
            "\n",
            "Edward: I never heard  bad word spoken aboutose. If anything, gave away too much of. I don't the or the Arch Philadelphia would ever hire a to. They never had a kind word for Lynn Abraham.\n",
            "\n",
            "Edward: I never heard  bad word spoken about Jewose. If anything, he gave away too much of himself. I don't know the Jewish community or the Archdiocese of Philadelphia would ever hire a Jew to speak. They never had a kind word for Lynn Abraham.\n",
            "  0% 1/7203 [00:00<1:36:30,  1.24it/s]\"... to us illiterate peasants,\" if you please.\n",
            "\n",
            "\"... to,\" if you please.\n",
            "\n",
            "\"... to you,\" if you please.\n",
            "  0% 2/7203 [00:01<53:34,  2.24it/s]  With three electoral votes this matters, not.\n",
            "\n",
            "With votes this matters, not.\n",
            "\n",
            "With electoral college votes this matters, not.\n",
            "  0% 3/7203 [00:01<40:21,  2.97it/s]Idiot. This kid needs a good introduction into the hard facts of life.\n",
            "\n",
            ". needs a good introduction the hard facts of.\n",
            "\n",
            "He needs a good introduction to the hard facts of reality.\n",
            "  0% 4/7203 [00:01<36:12,  3.31it/s]Careful Jim, you'll get censored.\n",
            "\n",
            ", you'll get.\n",
            "\n",
            "True, you'll get it.\n",
            "  0% 5/7203 [00:01<31:34,  3.80it/s]well that's rather disturbing\n",
            "\n",
            "well that's disturbing\n",
            "\n",
            "well that's sickening disturbing\n",
            "  0% 6/7203 [00:01<27:23,  4.38it/s]Allah is punishing his little soldiers.\n",
            "\n",
            " is punishing his little.\n",
            "\n",
            "He is punishing his little Muslim brother.\n",
            "  0% 7/7203 [00:02<26:17,  4.56it/s]The reporter. The guy clearly didn't want to talk to her but she kept persisting.\n",
            "\n",
            "The reporter. The want to to but kept persisting.\n",
            "\n",
            "The reporter. The editors want to listen to him but he kept persisting.\n",
            "  0% 8/7203 [00:02<28:42,  4.18it/s]who else: Those who manufacture flashy socks and tan shoes.  Bombardier execs Indigenous peoples...although he doesn't seem to be doing much to assist life on reserves other than allowing Chiefs to squirrel away money without getting caught\n",
            "\n",
            " else: manufacture flashy socks and shoes.ardier execs...although he doesn't seem to be doing much to assist life on reserves other than allowing to squirrel away money without getting caught\n",
            "\n",
            "Someone else: Chinese manufacture flashy socks and shoes. Bombardier execs....although he doesn't seem to be doing much to assist life on reserves other than allowing himself to squirrel away money without getting caught.\n",
            "  0% 9/7203 [00:02<42:13,  2.84it/s]\"We have great faith in your abilities and intent. We may not get everything we want but your invaluable experience will serve us well.\"  Who are the \"we\" in your comment. Certainly your not speaking for all Alaskans!\n",
            "\n",
            "\"We have great abilities and intent. We may not get everything we want but invaluable experience will serve us well.\" are the \"\" in your comment. Certainly your not for!\n",
            "\n",
            "\"We have great leadership abilities and intent. We may not get everything we want but our invaluable experience will serve us well.\"  You are the \"leader\" in your comment. Certainly your not speaking for me!\n",
            "100% 7203/7203 [05:57<00:00, 20.15it/s]\n",
            "test_total_loss: 0.8132601446858317\n",
            "train epoch:  1\n",
            "Batch_loss $0.3864:   2% 999/64822 [02:11<2:15:49,  7.83it/s]999\n",
            "More whining from the resident? racist, bigot, misogynist troll spewing his/her daily nonsense against all non-racists, bigots, misogynists, CONservatives, White Supremacists, et.al.\n",
            "\n",
            "More whining from the resident?, bigot,ist troll spewing his/her daily nonsense against all-ists, bigots,ists, CONservatives, Supremacists, et.al\n",
            "\n",
            "More whining from the resident? racist, bigot, misogynist troll spewing his/her daily nonsense against all non-whites, misogynists, CONservatives, White Supremacists, et.al.\n",
            "Batch_loss $0.3846:   3% 1999/64822 [04:24<2:16:33,  7.67it/s]1999\n",
            "Good to read Tom Bell again on the pages of ADN.  I hope to read more of his stories in the future.\n",
            "\n",
            "Good to read Bell again on the pages ofN  I hope to read more of his in the future\n",
            "\n",
            "Good to read John Bell again on the pages of ADN.  I hope to read more of his columns in the future.\n",
            "Batch_loss $0.3851:   5% 2999/64822 [06:39<2:13:44,  7.70it/s]2999\n",
            "Why wasn't Douglas Chin invited to meet Trump on the tarmac?  LOL\n",
            "\n",
            "Why wasn't Douglas invited to on the t?  LOL\n",
            "\n",
            "Why wasn't Douglas Chin invited to run on the tarmac?  LOL\n",
            "Batch_loss $0.3843:   6% 3999/64822 [08:49<2:20:19,  7.22it/s]3999\n",
            "Wynne salivates to see another source of taxation like cigarettes, alcohol (LCBO)... that is what this is all about\n",
            "\n",
            "Wynne salivates to see another source of taxation like, ()... that is what this is all about\n",
            "\n",
            "Wynne salivates to see another source of taxation like oil, gas (gasoline)... that is what this is all about.\n",
            "Batch_loss $0.3850:   8% 4999/64822 [11:01<2:06:23,  7.89it/s]4999\n",
            "Catholic separate schools in Alberta are 100% public funded, as they are in Ontario.\n",
            "\n",
            " separate in are 100% public funded, as they are in\n",
            "\n",
            "Catholic separate schools in Canada are 100% public funded, as they are in Canada.\n",
            "Batch_loss $0.3844:   9% 5999/64822 [13:10<2:12:59,  7.37it/s]5999\n",
            "Don is a dyed in the wool conservative.   Makes me shudder....     :-)\n",
            "\n",
            "Don is a in the   Makes me shudder....     :-)\n",
            "\n",
            "Don is a wolf in the sheepskin.   Makes me shudder....    :-)\n",
            "Batch_loss $0.3845:  11% 6999/64822 [15:20<2:02:29,  7.87it/s]6999\n",
            "Then the algorithm is quite civilized and I am most grateful for its consideration.  BTW.  Is the moderator's algorithm nature confirmed somewhere by the DP?  Thanks.\n",
            "\n",
            "Then the is quite and am most grateful for its consideration  BTW.  Is the's nature confirmed somewhere by the DP?  Thanks\n",
            "\n",
            "Then the comment is quite civil and I am most grateful for its consideration.  BTW.  Is the author's political nature confirmed somewhere by the DP?  Thanks.\n",
            "Batch_loss $0.3832:  12% 7999/64822 [17:32<1:59:02,  7.96it/s]7999\n",
            "Heaven forbid that he would keep his promise to provide health care coverage for EVERYONE that is much less expensive and much better. He didn't even try. Talk about a failure of leadership...\n",
            "\n",
            "Heaven forbid that would keep his promise to provide for EVERYONE that is much less expensive and much better didn't even try Talk about a failure of...\n",
            "\n",
            "Heaven forbid that he would keep his promise to provide healthcare for EVERYONE that is much less expensive and much better. He didn't even try. Talk about a failure of leadership...\n",
            "Batch_loss $0.3841:  14% 8999/64822 [19:42<2:04:33,  7.47it/s]8999\n",
            "Heroism aside, this should be a very stark warning. DO NOT GO TO THE United States. It is in chaos.\n",
            "\n",
            "ism aside, this should be a very stark warning. DO NOT GO TO It is in\n",
            "\n",
            "Socialism aside, this should be a very stark warning. DO NOT GO TO NK. It is inhumane.\n",
            "Batch_loss $0.3842:  15% 9999/64822 [21:51<1:53:50,  8.03it/s]9999\n",
            "I think its odd that female staff were forced to watch.\n",
            "\n",
            "I think its odd that staff were forced to watch\n",
            "\n",
            "I think its odd that female staff were forced to watch.\n",
            "Batch_loss $0.3847:  17% 10999/64822 [24:03<2:05:00,  7.18it/s]10999\n",
            "Main stream media.  So?\n",
            "\n",
            "Main.  So?\n",
            "\n",
            "Maintenance..  So?\n",
            "Batch_loss $0.3842:  19% 11999/64822 [26:12<1:52:55,  7.80it/s]11999\n",
            "Deflect much?  Harper is long gone!  This is entirely the Liberal's mess.    Geeze,  does every alt-left liberal say  \"Bu,  bu,  but  Harper!\"\n",
            "\n",
            "Def much?  Harper is long gone!  This is entirely the's mess    Gze,  does every alt- say  \"Bu,  bu,  but  Harper!\"\n",
            "\n",
            "Deflect much?  Harper is long gone!  This is entirely the left's mess.    Geeze,  does every alt-right say  \"Bu,  bu,  but  Harper!\"\n",
            "Batch_loss $0.3846:  20% 12999/64822 [28:22<1:53:44,  7.59it/s]12999\n",
            "Those on Obamacare that had their plans subsidized by the government experienced lower cost.  The rest of us had higher costs.\n",
            "\n",
            "Those on that had their plans subsidized by the government experienced lower cost  The rest of had higher costs\n",
            "\n",
            "Those on fixed incomes that had their plans subsidized by the government experienced lower cost.  The rest of us had higher costs.\n",
            "Batch_loss $0.3844:  22% 13999/64822 [30:36<1:48:25,  7.81it/s]13999\n",
            "It is high time that we changed our system and began to elect judges, just like they do in the United States. The ones that give lenient or milquetoast  rulings could be given the boot by the electorate, same that let those shyster lawyers get violent criminals off on technicalities.\n",
            "\n",
            "It is high time that changed our system and began to elect judges, just like they do in The ones that give lenient orquetoast  rulings could be given the boot by the electorate, same that let those get violent criminals off on technicalities\n",
            "\n",
            "It is high time that Canada changed our system and began to elect judges, just like they do in Saudi Arabia. The ones that give lenient orquetoast  rulings could be given the boot by the electorate, same that let those Saudi judges get violent criminals off on technicalities.\n",
            "Batch_loss $0.3845:  23% 14999/64822 [32:47<1:50:45,  7.50it/s]14999\n",
            "No Catholic Church should ever shield illegal aliens.  This gathering is a toxic cancer.  This is the sort of left-wing Protestant nonsense the Church needs to not touch, it's a political tarbbaby.\n",
            "\n",
            "No Church should ever shield  This gathering is  This is the sort of left-wing nonsense the Church needs to not touch, it's a political tarbbaby\n",
            "\n",
            "No Catholic Church should ever shield pedophile priests.  This gathering is pedophile. This is the sort of left-wing Catholic nonsense the Church needs to not touch, it's a political tarbbaby.\n",
            "Batch_loss $0.3847:  25% 15999/64822 [35:00<1:40:11,  8.12it/s]15999\n",
            "Tommy quacks like a racist for sure.\n",
            "\n",
            "Tommy qu like a for sure\n",
            "\n",
            "Tommy quacks like a fool for sure.\n",
            "Batch_loss $0.3846:  26% 16999/64822 [37:10<1:41:54,  7.82it/s]16999\n",
            "No thats completely incorrect. Body dysmorphia is an anxiety disorder based on a distorted view of how they look. The entire hysteria around \"gender identity\" is completely manufactured and based on feelings.\n",
            "\n",
            "No thats completely incorrect is an based on a distorted view of how look The entire hysteria around \" identity\" is completely manufactured and based on feelings\n",
            "\n",
            "No thats completely incorrect. Mental illness is an illness based on a distorted view of how people look. The entire hysteria around \"social identity\" is completely manufactured and based on feelings.\n",
            "Batch_loss $0.3845:  28% 17999/64822 [39:24<2:15:04,  5.78it/s]17999\n",
            "Blacks are intellectual inferiors even to Mexicans!\n",
            "\n",
            "Bl are inferiors even to!\n",
            "\n",
            "Blacks are our inferiors even to whites!\n",
            "Batch_loss $0.3848:  29% 18999/64822 [41:35<1:38:03,  7.79it/s]18999\n",
            "sounds corrupt.  but there are different types of corruption.   there is a big difference between overpaying $300 million dollars and getting the lights back on in Puerto Rico by Xmas and paying $300 million dollars and getting nothing.\n",
            "\n",
            "sounds corrupt  but there are different types of corruption   there is a big difference between overpaying $300 million dollars and getting the back on by X and paying $300 million dollars and getting nothing\n",
            "\n",
            "sounds corrupt.  but there are different types of corruption.   there is a big difference between overpaying $300 million dollars and getting the money back on time by Xmas and paying $300 millions dollars to get nothing.\n",
            "Batch_loss $0.3850:  31% 19999/64822 [43:46<1:43:00,  7.25it/s]19999\n",
            "Liberals: Tell us sanctimonoiusly and self-righteously how the Democrats'  smear job and lying coverup is not a disgrace\n",
            "\n",
            "als: Tell us sanctimonoiusly and self-eously how the'  smear job and coverup is not a disgrace\n",
            "\n",
            "Liberals: Tell us sanctimonoiuslyly and self-righteously how the media'  smear job and Trump coverup is not a disgrace.\n",
            "Batch_loss $0.3856:  32% 20999/64822 [46:00<1:33:37,  7.80it/s]20999\n",
            "PBS is as unbiased as the RG is.\n",
            "\n",
            "P is as as the is\n",
            "\n",
            "PFD is as dangerous as the military is.\n",
            "Batch_loss $0.3857:  34% 21999/64822 [48:11<1:32:48,  7.69it/s]21999\n",
            "Nope. NPR. EO's lawyer explicitly said churches should be -forced- to accommodate gay weddings.\n",
            "\n",
            "Nope. EO's lawyer explicitly said should be -forced- to accommodate weddings\n",
            "\n",
            "Nope. AG EO's lawyer explicitly said churches should be -forced- to accommodate gay weddings.\n",
            "Batch_loss $0.3857:  35% 22999/64822 [50:23<1:27:45,  7.94it/s]22999\n",
            "If by race, almost all are White Race. Look at the arrest records or Most Wanted. Some add Latino or Hispanic after the White Race part. But not all.\n",
            "\n",
            "If by, almost all are. Look at the arrest records or Most Wanted. Some add or after the part But not all\n",
            "\n",
            "If by race, almost all are Hispanic. Look at the arrest records or Most Wanted. Some add white or black after the Hispanic part. But not all.\n",
            "Batch_loss $0.3858:  37% 23999/64822 [52:34<1:27:06,  7.81it/s]23999\n",
            "Who says he was a \"human being\"?\n",
            "\n",
            "Who says was a \" being\"?\n",
            "\n",
            "Who says he was a \"human being\"?\n",
            "Batch_loss $0.3858:  39% 24999/64822 [54:45<1:24:40,  7.84it/s]24999\n",
            "yup, Racism will never end or hate of some other for any reason. It's human\n",
            "\n",
            "yup,ism will never end or hate of some other for any reason It's\n",
            "\n",
            "yup, racismism will never end or hate of some other for any reason. It's 2017.\n",
            "Batch_loss $0.3860:  40% 25999/64822 [56:57<1:21:31,  7.94it/s]25999\n",
            "$8896.00 per month income and he hangs out on Government Hill.  Hmmm....\n",
            "\n",
            "$8896.00 per and hangs out on Hill  Hmmm....\n",
            "\n",
            "$8896.00 per month and she hangs out on Capitol Hill.  Hmmm....\n",
            "Batch_loss $0.3861:  42% 26999/64822 [59:08<1:26:26,  7.29it/s]26999\n",
            "Wow.   Do surveillance cameras installed by global surveillance and intelligence firms count?\n",
            "\n",
            "Wow   Do surveillance cameras installed by surveillance and firms count?\n",
            "\n",
            "Wow.   Do surveillance cameras installed by military surveillance and intelligence firms count?\n",
            "Batch_loss $0.3862:  43% 27999/64822 [1:01:22<1:17:21,  7.93it/s]27999\n",
            "Addressing the wider issues beyond the charges in this news report, s\n",
            "\n",
            "Addressing the wider issues the in news, s\n",
            "\n",
            "Addressing the wider issues with the media in fake news media, s\n",
            "Batch_loss $0.3862:  45% 28999/64822 [1:03:35<1:16:24,  7.81it/s]28999\n",
            "LOL  No.\n",
            "\n",
            "LOL \n",
            "\n",
            "LOL  Funny.\n",
            "Batch_loss $0.3863:  46% 29999/64822 [1:05:50<1:19:47,  7.27it/s]29999\n",
            "Well kirk little stooges raise our assesed property value this raising property taxes...\n",
            "\n",
            "Well little stoes raise our assesed property value this raising...\n",
            "\n",
            "Well stupid little stooges raise our assesed property value this raising taxes...\n",
            "Batch_loss $0.3864:  48% 30999/64822 [1:08:02<1:13:15,  7.69it/s]30999\n",
            "That's right, now to fix this problem here you go: https://petitions.parl.gc.ca/en/Petition/Details?Petition=e-337\n",
            "\n",
            "That's right, now to fix this problem here you go: https://petitions...//Petition/Details?Petition=e-337\n",
            "\n",
            "That's right, now to fix this problem here you go: https://petitions.alaska.senate.gov/uploads/Petition/Details?Petition=e-337\n",
            "Batch_loss $0.3868:  49% 31999/64822 [1:10:16<1:11:41,  7.63it/s]31999\n",
            "Get lost loser Trump called them n their crap It is they who will pay the price when no one shows up\n",
            "\n",
            "Get n their crap It is they who will pay the price when no one shows up\n",
            "\n",
            "Get over yourself n their crap It is they who will pay the price when no one shows up.\n",
            "Batch_loss $0.3868:  51% 32999/64822 [1:12:28<1:09:27,  7.64it/s]32999\n",
            "\"One woman in Park Blocks – who refused to give her name or be recorded – says she fears more police will scare homeless people away from the area, robbing them of community.\"  http://klcc.org/post/more-eugene-police-assigned-downtown-area\n",
            "\n",
            "\"One in Park Blocks âĢĵ who refused to give her name or be âĢĵ says she fears more will scare people away from the area, robbing them of.\"  http://ccorg/post/more-ugene-\n",
            "\n",
            "\"One woman in Park Blocks – who refused to give her name or be identified – says she fears more fireworks will scare local people away from the area, robbing them of their jobs.\"  http://cnn.org/post/more-jamesugene-violence\n",
            "Batch_loss $0.3870:  52% 33999/64822 [1:14:39<1:05:20,  7.86it/s]33999\n",
            "I don't think the islamists see their religion as peaceful at all!\n",
            "\n",
            "I don't think the see their as peaceful at all!\n",
            "\n",
            "I don't think the Muslims see their religion as peaceful at all!\n",
            "Batch_loss $0.3870:  54% 34999/64822 [1:16:50<1:06:07,  7.52it/s]34999\n",
            "Glad that the corvid won and enjoyed the commentary comparing popular vote to \"Boaty McBoatface\"\n",
            "\n",
            "Glad that thevid won and enjoyed the commentary comparing to \"y McBface\"\n",
            "\n",
            "Glad that the Trudvik won and enjoyed the commentary comparing him to \"Snowy McBuckface\"\n",
            "Batch_loss $0.3870:  56% 35999/64822 [1:18:59<1:00:45,  7.91it/s]35999\n",
            "Its all about special snowflake status and privileges.  And equal outcomes will only work one way - fields with more men then women.  And don't expect any rational discussion about why there are differences in men's and women's choices, speaking in general terms of course.\n",
            "\n",
            "Its all about special snowflake status and privileges  And equal outcomes will only work one way - fields with then  And don't expect any rational discussion about why there are differences in's and's choices, speaking in general terms of course\n",
            "\n",
            "Its all about special snowflake status and privileges.  And equal outcomes will only work one way - fields with females then males. And don't expect any rational discussion about why there are differences in women's and men's choices, speaking in general terms of course.\n",
            "Batch_loss $0.3872:  57% 36999/64822 [1:21:10<1:00:47,  7.63it/s]36999\n",
            "Sher-e-Hindustan: Sources please. Further, many Africans are Muslim, but maybe you're not aware of this? I suspect the biggest factors underlying high crime/murder rates are poverty and inequality.\n",
            "\n",
            "Sher-e-: Sources please Further, many are, but maybe you're not aware of this? I suspect the biggest factors underlying high crime/murder rates are poverty and inequality\n",
            "\n",
            "Sher-e-Hindustan: Sources please. Further, many Muslims are immigrants, but maybe you're not aware of this? I suspect the biggest factors underlying high crime/murder rates are poverty and inequality.\n",
            "Batch_loss $0.3872:  59% 37999/64822 [1:23:20<57:11,  7.82it/s]37999\n",
            "without a trace. PC police hard at work.\n",
            "\n",
            "without a trace police hard at work\n",
            "\n",
            "without a trace Canadian police hard at work\n",
            "Batch_loss $0.3873:  60% 38999/64822 [1:25:30<55:28,  7.76it/s]38999\n",
            "Trump is going to pay and supply the labor for the wall that is going to be built in Canada - he's got to create jobs for all his poor white voters who expect jobs PDQ\n",
            "\n",
            "Trump is going to pay and supply the labor for the that is going to be built -'s got to create jobs for all his poor voters who expect jobs PD\n",
            "\n",
            "Trump is going to pay and supply the labor for the rail for the wall that is going in - he's got to create jobs for all his poor white voters who expect jobs PD.\n",
            "Batch_loss $0.3873:  62% 39999/64822 [1:27:40<55:38,  7.44it/s]39999\n",
            "Speaking as a MAN - the husband had some nerve.\n",
            "\n",
            "Speaking as a - the had some\n",
            "\n",
            "Speaking as a male - the guy had some class.\n",
            "Batch_loss $0.3873:  63% 40999/64822 [1:29:51<51:17,  7.74it/s]40999\n",
            "Tallman was not 'escaping' as the lead line states. He was assaulting Larson for the third or fourth time.\n",
            "\n",
            "T was not 'esc' as the lead line states was for the or time\n",
            "\n",
            "Tray was not 'escaped' as the lead line states. He was suspended for the game or jail time.\n",
            "Batch_loss $0.3877:  65% 41999/64822 [1:32:03<50:52,  7.48it/s]41999\n",
            "A drunk woman gets into a cab and is so infatuated with the cab driver, she starts being intimate with him...   Yeah right. That sounds plausible.\n",
            "\n",
            "A gets into a cab and is so infatuated with the cab driver, she starts being with...   Yeah right That sounds plausible\n",
            "\n",
            "A woman gets into a cab and is so infatuated with the cab driver, she starts being intimate with him...   Yeah right. That sounds plausible.\n",
            "Batch_loss $0.3879:  66% 42999/64822 [1:34:12<46:00,  7.91it/s]42999\n",
            "Normal wear and tear; the place is quite old, so this to be expected.\n",
            "\n",
            "Normal wear and tear; the place is quite, so this to be expected\n",
            "\n",
            "Normal wear and tear; the place is quite old, so this to be expected.\n",
            "Batch_loss $0.3879:  68% 43999/64822 [1:36:23<46:34,  7.45it/s]43999\n",
            "You just stepped on your own cojones there Sparky.\n",
            "\n",
            "You just stepped on your own co Sparky\n",
            "\n",
            "You just stepped on your own coven Sparky.\n",
            "Batch_loss $0.3881:  69% 44999/64822 [1:38:31<42:00,  7.87it/s]44999\n",
            "And we can store all our grain in them.\n",
            "\n",
            "And we can store all our in them\n",
            "\n",
            "And we can store all our guns in them.\n",
            "Batch_loss $0.3881:  71% 45999/64822 [1:40:40<39:36,  7.92it/s]45999\n",
            "Climate change is scary business and left unchecked will lead to some pretty catastrophic consequences.  Putting your head in the sand, won't change the reality of things.   https://www.skepticalscience.com/sea-level-rise-predictions.htm\n",
            "\n",
            " change is scary and left unchecked will lead to some pretty catastrophic consequences  Putting your head in the sand, won't change the reality of things   https://www.sicalcom/-level--predictionshtm\n",
            "\n",
            "Climate change is scary, and left unchecked will lead to some pretty catastrophic consequences.  Putting your head in the sand, won't change the reality of things.   https://www.skepticalscience.com/global-level-warming-predictions.htm\n",
            "Batch_loss $0.3883:  73% 46999/64822 [1:42:48<38:12,  7.77it/s]46999\n",
            "hey justin, you are about a week late to the party, the world is already talking response, boy this loser pM never has timing\n",
            "\n",
            "hey justin, you are about a late to the party, the is already response, this p never has timing\n",
            "\n",
            "hey justin, you are about a year late to the party, the guy is already his response, boy this guy paul never has timing\n",
            "Batch_loss $0.3885:  74% 47999/64822 [1:44:54<33:34,  8.35it/s]47999\n",
            "Seems we do not hear too much about Coptic, or anyone but Muslims these days.   Be it the PRESS OR THE UN OR CERTAIN POLITICIANS.\n",
            "\n",
            "Seems we do not hear too much about, or anyone but these days   Be it the OR THE OR CERTAINIC\n",
            "\n",
            "Seems we do not hear too much about Muslims, or anyone but Christians these days.   Be it the USA OR THE USA OR CERTAIN SOULIC.\n",
            "Batch_loss $0.3887:  76% 48999/64822 [1:47:02<33:49,  7.80it/s]48999\n",
            "I wonder how many people have a drug charge from fauntino's era as chief of police.... This is quite hypocritical\n",
            "\n",
            "I wonder how many people have a charge from faunt's era as of.... This is quite hypocritical\n",
            "\n",
            "I wonder how many people have a criminal charge from fauntlin's era as Minister of Health.... This is quite hypocritical.\n",
            "Batch_loss $0.3888:  77% 49999/64822 [1:49:08<32:44,  7.55it/s]49999\n",
            "You're right Kon man. (I can't believe I'm typing that!) Maybe Charles meant Medicaid, which is generally free to the recipient. Of course somebody (the taxpayer, have to pay for it.\n",
            "\n",
            "You're right Kon (I can't believe I'm typing that!) Maybe meant, which is generally free to the recipient Of course somebody (the taxpayer, have to pay for it\n",
            "\n",
            "You're right Kon man. (I can't believe I'm typing that!) Maybe he meant alcohol, which is generally free to the recipient. Of course somebody (the taxpayer, have to pay for it.\n",
            "Batch_loss $0.3888:  79% 50999/64822 [1:51:20<30:06,  7.65it/s]50999\n",
            "The repeated use of the argument that currency fluctuations are the source of budget shortages does not make it more convincing. If less money comes into the GC because of the exchange rate, less money will need to go out for the same reason. Still puzzled.\n",
            "\n",
            "The repeated use of the argument that fluctuations are the source of shortages does not make it more convincing If less money comes into the because of, less money will need to go out for the same reason. Still puzzled\n",
            "\n",
            "The repeated use of the argument that market fluctuations are the source of labour shortages does not make it more convincing. If less money comes into the market because of inflation, less money will need to go out for the same reason. Still puzzled.\n",
            "Batch_loss $0.3888:  80% 51999/64822 [1:53:29<27:23,  7.80it/s]51999\n",
            ".  McCallum  = Canada's Merkel  He apologizes every time he looks in the mirror  He is a Social Justice Warrior.  Here him cry..\n",
            "\n",
            ".  McCallum  ='s Merkel apologizes every time in the is a Social Justice Warrior  Here him cry..\n",
            "\n",
            "Mr.  McCallum  =  Merkel's Merkel she apologizes every time she speaks in the media  She is a Social Justice Warrior.  Here him cry..\n",
            "Batch_loss $0.3890:  82% 52999/64822 [1:55:39<24:52,  7.92it/s]52999\n",
            "Nope.  Never even been to Pueblo.  I'll be too busy working to pay for your food stamps.\n",
            "\n",
            "Nope.  Never even been to  I'll be too busy working to pay for your food stamps\n",
            "\n",
            "Nope.  Never even been to Hawaii.  I'll be too busy working to pay for your food stamps.\n",
            "Batch_loss $0.3890:  83% 53999/64822 [1:57:48<23:04,  7.82it/s]53999\n",
            "\"It all boils down to \"White privilege\". Please explain in as much detail as Civil allows.\n",
            "\n",
            "\"It all boils down to \" privilege\". Please explain in as much detail as allows\n",
            "\n",
            "\"It all boils down to \"white privilege\". Please explain in as much detail as your mind allows.\n",
            "Batch_loss $0.3890:  85% 54999/64822 [1:59:58<20:26,  8.01it/s]54999\n",
            "I had an ex girlfriend that was so bad she would even tailgate police officers. She had no idea she was doing it. Very bizarre but backs up your observation. They don't have the same spatial capabilities as men.\n",
            "\n",
            "I had an ex that was so bad she would even tailgate police officers She had no idea she was doing it. Very bizarre but backs up your observation They don't have the same capabilities as\n",
            "\n",
            "I had an ex girlfriend that was so bad she would even tailgate police officers. She had no idea she was doing it. Very bizarre but backs up your observation. They don't have the same thinking capabilities as women.\n",
            "Batch_loss $0.3890:  86% 55999/64822 [2:02:08<18:47,  7.82it/s]55999\n",
            "Got ya\n",
            "\n",
            " ya\n",
            "\n",
            "Me ya.\n",
            "Batch_loss $0.3892:  88% 56999/64822 [2:04:18<17:18,  7.53it/s]56999\n",
            "Prayers to the family and friends. We do have to seek comfort in our Living God and Savior for He comforts the ones who are mourning.\n",
            "\n",
            "Pers to the family and friends We do have to seek comfort in our and for comforts the ones who are mourning\n",
            "\n",
            "Prayers to the family and friends. We do have to seek comfort in our Lord and Savior for healing comforts the ones who are mourning.\n",
            "Batch_loss $0.3891:  89% 57999/64822 [2:06:29<14:04,  8.08it/s]57999\n",
            "There is only one choice for President, and that is Clinton. Trump has proved without doubt that he is not fit to be President. Trump would be a disaster.\n",
            "\n",
            "There is only one choice for, and that is Clinton Trump has proved without doubt that is not fit to be Trump would be a disaster\n",
            "\n",
            "There is only one choice for President, and that is Clinton. Trump has proved without doubt that he is not fit to be President. Trump would be a disaster.\n",
            "Batch_loss $0.3891:  91% 58999/64822 [2:08:39<12:07,  8.00it/s]58999\n",
            "Supply management is obsolete in 2017  as it is a protective, preferential, old dairy farmers'club where \"grandfathered \" protection  is king/queen.  In consequence, Customers pay too much for  milk, cheese and any other dairy product.\n",
            "\n",
            "Supply management is obsolete in  as it is a protective, preferential, old' where \"grandfathered \" protection  is/  In consequence, Customers pay too much for  milk, cheese and any other product\n",
            "\n",
            "Supply management is obsolete in Canada  as it is a protective, preferential, old boys' club where \"grandfathered \" protection  is king/control.  In consequence, Customers pay too much for  milk, cheese and any other dairy product.\n",
            "Batch_loss $0.3890:  93% 59999/64822 [2:10:48<10:37,  7.57it/s]59999\n",
            "Double standard? You must not have noticed that only women get pregnant.  Might wanna work on your anger issues.\n",
            "\n",
            " standard? You must not have noticed that only  Might wanna work on your anger issues\n",
            "\n",
            "White male standard? You must not have noticed that only.  Might wanna work on your anger issues.\n",
            "Batch_loss $0.3890:  94% 60999/64822 [2:12:58<07:57,  8.01it/s]60999\n",
            "He reflects the powerful Masculinity of the Maleness of God.  More than one of our Sacred Leaders have indicated the church needs to be more masculine.\n",
            "\n",
            "He reflects the powerful of theeness of God  More than one of our Sacred Leaders have indicated the needs to be more\n",
            "\n",
            "He reflects the powerful wisdom of the Femineness of God.  More than one of our Sacred Leaders have indicated the Church needs to be more inclusive.\n",
            "Batch_loss $0.3890:  96% 61999/64822 [2:15:09<06:22,  7.37it/s]61999\n",
            "Your not allowed to use \"you people\". Oops, you meant WHITE people,carry on.\n",
            "\n",
            "Your not allowed to use \"you\". Oops, you meant,carry on\n",
            "\n",
            "Your not allowed to use \"you're white\". Oops, you meant white,carry on.\n",
            "Batch_loss $0.3890:  97% 62999/64822 [2:17:19<03:52,  7.85it/s]62999\n",
            "I can, Obama's stabbing Israel in the back at the UN.  It completely denied Israel's right to historical Jewish area of Jerusalem and denied Jewish holy areas in Jerusalem.\n",
            "\n",
            " can, Obama's stabbing in the back at the  It completely denied's right to historical area of Jerusalem and denied areas in Jerusalem\n",
            "\n",
            "Jews can, Obama's stabbing him in the back at the UN.  It completely denied Israel's right to historical Jewish area of Jerusalem and denied Jewish areas in Jerusalem.\n",
            "Batch_loss $0.3889:  99% 63999/64822 [2:19:29<01:50,  7.44it/s]63999\n",
            "Why?  If I feel sharia law is preferable to common law, that an Islamic theocracy is preferable to secular society, then I will not leave.  Instead, I will work and agitate until, little by little, my goals are realized.\n",
            "\n",
            "Why?  If feel is preferable to, that an the is preferable to, then I will not leave  Instead, I will work and agitate until, little by little, my goals are realized\n",
            "\n",
            "Why?  If I feel Islam is preferable to Christianity, that an Allah the Prophet is preferableto Mohammed, then I will not leave.  Instead, I will work and agitate until, little by little, my goals are realized.\n",
            "Batch_loss $0.3890: 100% 64822/64822 [2:21:16<00:00,  7.65it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"Bart_Label.py\", line 8, in <module>\n",
            "    train_generator(batch_size=3,max_length=64, lr=1e-5, epochs=3 ,mode=\"Bart\",attention_layer=10, save=args.source_folder+\"/Bart_test_label_attention_mean_6400\",drop_q=\"mean\",drop_mode=\"attention\",drop_classifier=args.source_folder+\"/Roberta_Kaggle_64\")\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Training/Training.py\", line 212, in train_generator\n",
            "    torch.save(model.state_dict(), save+str(epoch))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 377, in save\n",
            "    with _open_file_like(f, 'wb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 231, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 212, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "OSError: [Errno 107] Transport endpoint is not connected: 'generations/Bart_test_label_attention_mean_6401'\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "python3: can't open file 'Transfer.py': [Errno 107] Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "python3: can't open file 'Transfer_WR_Full.py': [Errno 107] Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "python3: can't open file 'Transfer_WR_50.py': [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train the transfer pipeline and generate pairs using style transfer and word replacement.**\n",
        "###Results are found in folders Code/generations.\n",
        "######Note: Generating modified comments for all original comments in the dataset can take a long time.\n"
      ],
      "metadata": {
        "id": "rvcBw6OL0vWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x Tables.sh"
      ],
      "metadata": {
        "id": "kFJYZkkr26EZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./Tables.sh"
      ],
      "metadata": {
        "id": "6wmlzx4A7Y3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7bfd8f-e7b1-4058-886d-39607780202e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 100% 570/570 [00:00<00:00, 2.97MB/s]\n",
            "Downloading: 100% 420M/420M [00:05<00:00, 77.6MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 673kB/s] \n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 149kB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 121, in __init__\n",
            "    data_train = pd.read_csv(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/../../Datasets/Kaggle_Toxicity/Large/train_preprocessed.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"Robustness_Transfer.py\", line 44, in <module>\n",
            "    data_pool = Data_Pool(data_sources={\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 124, in __init__\n",
            "    data_train = pd.read_csv(dirname + \"/Kaggle_Toxicity/train.csv\")\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Kaggle_Toxicity/train.csv'\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 121, in __init__\n",
            "    data_train = pd.read_csv(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/../../Datasets/Kaggle_Toxicity/Large/train_preprocessed.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"Robustness_Transfer.py\", line 44, in <module>\n",
            "    data_pool = Data_Pool(data_sources={\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 124, in __init__\n",
            "    data_train = pd.read_csv(dirname + \"/Kaggle_Toxicity/train.csv\")\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Kaggle_Toxicity/train.csv'\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 121, in __init__\n",
            "    data_train = pd.read_csv(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/../../Datasets/Kaggle_Toxicity/Large/train_preprocessed.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"Robustness_Transfer.py\", line 44, in <module>\n",
            "    data_pool = Data_Pool(data_sources={\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 124, in __init__\n",
            "    data_train = pd.read_csv(dirname + \"/Kaggle_Toxicity/train.csv\")\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Kaggle_Toxicity/train.csv'\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 121, in __init__\n",
            "    data_train = pd.read_csv(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/../../Datasets/Kaggle_Toxicity/Large/train_preprocessed.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"Robustness_Transfer.py\", line 44, in <module>\n",
            "    data_pool = Data_Pool(data_sources={\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 124, in __init__\n",
            "    data_train = pd.read_csv(dirname + \"/Kaggle_Toxicity/train.csv\")\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Kaggle_Toxicity/train.csv'\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 121, in __init__\n",
            "    data_train = pd.read_csv(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/../../Datasets/Kaggle_Toxicity/Large/train_preprocessed.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"Robustness_Transfer.py\", line 67, in <module>\n",
            "    data_pool = Data_Pool(data_sources={\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 124, in __init__\n",
            "    data_train = pd.read_csv(dirname + \"/Kaggle_Toxicity/train.csv\")\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Kaggle_Toxicity/train.csv'\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 121, in __init__\n",
            "    data_train = pd.read_csv(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/../../Datasets/Kaggle_Toxicity/Large/train_preprocessed.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"Robustness_Transfer.py\", line 53, in <module>\n",
            "    data_pool = Data_Pool(data_sources={\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 124, in __init__\n",
            "    data_train = pd.read_csv(dirname + \"/Kaggle_Toxicity/train.csv\")\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Kaggle_Toxicity/train.csv'\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 121, in __init__\n",
            "    data_train = pd.read_csv(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/../../Datasets/Kaggle_Toxicity/Large/train_preprocessed.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"Robustness_Transfer.py\", line 60, in <module>\n",
            "    data_pool = Data_Pool(data_sources={\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 124, in __init__\n",
            "    data_train = pd.read_csv(dirname + \"/Kaggle_Toxicity/train.csv\")\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Kaggle_Toxicity/train.csv'\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 121, in __init__\n",
            "    data_train = pd.read_csv(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/../../Datasets/Kaggle_Toxicity/Large/train_preprocessed.csv'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"Robustness_Transfer.py\", line 44, in <module>\n",
            "    data_pool = Data_Pool(data_sources={\n",
            "  File \"/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Datasets.py\", line 124, in __init__\n",
            "    data_train = pd.read_csv(dirname + \"/Kaggle_Toxicity/train.csv\")\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 680, in read_csv\n",
            "    return _read(filepath_or_buffer, kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 575, in _read\n",
            "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 933, in __init__\n",
            "    self._engine = self._make_engine(f, self.engine)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\", line 1217, in _make_engine\n",
            "    self.handles = get_handle(  # type: ignore[call-overload]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\", line 789, in get_handle\n",
            "    handle = open(\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/fairness-feedback-nlp-master/Code/Transfer/Datasets/Kaggle_Toxicity/train.csv'\n"
          ]
        }
      ]
    }
  ]
}
